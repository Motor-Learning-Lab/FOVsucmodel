{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import colormaps as cmaps \n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.patches import Rectangle, FancyArrowPatch\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input some set up\n",
    "#target point(-2.85,0.108).position point(-2.85,-0.623),width0.71,height1.256,and the rader postion0.45,\n",
    "# Define the target point\n",
    "target_x = -2\n",
    "rader_x = 0.45\n",
    "target_y = 0\n",
    "\n",
    " # Define the vertices of the hexagon in (x,y) coordinate pairs\n",
    "#vertices = [(-2.0035, -1.27), (-2.0035, 1.486), (-0.8405,  1.486), (-0.8405, 1.123), (0.8465, 1.123), (0.8465, -1.270)]\n",
    "vertices = [(-2.5, -1.37), (-2.5, 1.486), (-0.04,  1.486), (-0.04, 1.123), (0.8465, 1.123), (0.8465, -1.37)]\n",
    "# Define the target area position, width, and height.target point(-2.85,0.108).position point(-2.85,-0.623),width0.71,height1.256,and the rader postion error 0.32\n",
    "rect_pos = (-2.2,-0.314 )\n",
    "rect_width = 0.35\n",
    "rect_height = 0.628\n",
    "\n",
    "criterion_dis = 4\n",
    "criterion_Yr = 0.314\n",
    "\n",
    "x_range = (-2.8,1.8)\n",
    "y_range = (-1.8,1.8)\n",
    "time_range = (0,180)\n",
    "Y_range = (0,0.5)\n",
    "\n",
    "# Define the path to the directory containing the data, the path to store the output \n",
    "Baselinedata_dir = \"D:/FOV2/Baselinedata/\"\n",
    "Baselinestore_dir = \"D:/FOV2/BRWanalysis/data/Baseline/\"\n",
    "\n",
    "Rotationdata_dir = \"D:/FOV2/Rotationdata/\"\n",
    "Rotationstore_dir = \"D:/FOV2/BRWanalysis/data/Rotation/\"\n",
    "\n",
    "Washoutdata_dir = \"D:/FOV2/Washoutdata/\"\n",
    "Washoutstore_dir = \"D:/FOV2/BRWanalysis/data/Washout/\"\n",
    "\n",
    "\n",
    "ReRotationdata_dir = \"D:/FOV2/ReRotationdata/\"\n",
    "ReRotationstore_dir = \"D:/FOV2/BRWanalysis/data/ReRotaion/\"\n",
    "\n",
    "ReWashoutdata_dir = \"D:/FOV2/ReWashoutdata/\"\n",
    "ReWashoutstore_dir = \"D:/FOV2/BRWanalysis/data/ReWashout/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReWashout_new_df_dir = os.path.join(\"D:/FOV2/BRWanalysis/data/ReWashout/new_df/\")\n",
    " # Create the directory if it does not exist\n",
    "if not os.path.exists(ReWashout_new_df_dir):\n",
    "    os.makedirs(ReWashout_new_df_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All valid data points for each fish in the Rewashout session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the fish IDs in Washout session\n",
    "for fish_id in ['fish9','fish10']:\n",
    "    # Create an empty list to store the data frames\n",
    "    dfs = []\n",
    "\n",
    "    # Loop over the directories in the data directory\n",
    "    for dir_name in os.listdir(ReWashoutdata_dir):\n",
    "        # Set the path to the directory\n",
    "        dir_path = os.path.join(ReWashoutdata_dir, dir_name, fish_id)\n",
    "        # Check if the directory exists\n",
    "        if os.path.isdir(dir_path):\n",
    "            # Loop over the CSV files in the directory\n",
    "            for file_name in os.listdir(dir_path):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    # Set the path to the CSV file\n",
    "                    file_path = os.path.join(dir_path, file_name)\n",
    "                    # Load the CSV file into a DataFrame\n",
    "                    df = pd.read_csv(file_path)\n",
    "\n",
    "                    # Add the date and file name columns\n",
    "                    df[\"date\"] = dir_name\n",
    "                    df[\"experiment_id\"] = file_name.split(\".\")[0]\n",
    "                    df[\"fish_id\"] = fish_id\n",
    "                    df['trial_id'] = file_name.split('__')[-1].split('.')[0]\n",
    "                    # Append the DataFrame to the list\n",
    "                    dfs.append(df)\n",
    "\n",
    "    # Concatenate the DataFrames in the list\n",
    "    combined_df = pd.concat(dfs)\n",
    "\n",
    "    # Remove junk frames with no goldfish activity detected\n",
    "    new_df = combined_df[(combined_df[\"Xf\"] != 0) & (combined_df[\"Yf\"] != 0)]\n",
    "\n",
    "    # Set the path to the CSV file to store the new_df\n",
    "    new_df_path = os.path.join(ReWashout_new_df_dir, f\"{fish_id}_ReWashout_new_df.csv\")\n",
    "    # Save the new_df to the CSV file\n",
    "    new_df.to_csv(new_df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the DataFrames\n",
    "ReWashoutdfs = []\n",
    "\n",
    "# Loop over the fish IDs\n",
    "for fish_id in ['fish9','fish10']:\n",
    "    # Set the path to the new_df table for the fish\n",
    "    new_df_path = os.path.join (ReWashout_new_df_dir, f\"{fish_id}_ReWashout_new_df.csv\")\n",
    "    # Load the new_df table into a DataFrame\n",
    "    df = pd.read_csv(new_df_path)\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    ReWashoutdfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames in the list\n",
    "all_ReWashoutfish_df = pd.concat(ReWashoutdfs)\n",
    "\n",
    "# Reset the DataFrame index to start from 0\n",
    "all_ReWashoutfish_df = all_ReWashoutfish_df.reset_index(drop=True)\n",
    "# Define the path to the CSV file to store the all_fish_df\n",
    "all_ReWashoutfish_df_path = os.path.join(ReWashout_new_df_dir, \"allReWashoutfish_df.csv\")\n",
    "# Save the all_fish_df to the CSV file\n",
    "all_ReWashoutfish_df.to_csv(all_ReWashoutfish_df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\1061915221.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['time'][0] = 0  # set first time value to 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\1061915221.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['time'][i] = all_ReWashoutfish_df['time'][i-1] + diff\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\1061915221.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.09562110899999965' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReWashoutfish_df['time'][i] = all_ReWashoutfish_df['time'][i-1] + diff\n"
     ]
    }
   ],
   "source": [
    "# create time column, calculate the real time of each experiment\n",
    "all_ReWashoutfish_df['time'] = 0  # initialize time column with 0\n",
    "all_ReWashoutfish_df['time'][0] = 0  # set first time value to 0\n",
    "\n",
    "for i in range(1, len(all_ReWashoutfish_df)):\n",
    "    diff = all_ReWashoutfish_df['t'][i] - all_ReWashoutfish_df['t'][i-1]\n",
    "    if diff > 1.5 or diff < 0 :\n",
    "        if all_ReWashoutfish_df['experiment_id'][i]!=all_ReWashoutfish_df['experiment_id'][i-1]:\n",
    "            all_ReWashoutfish_df['time'][i] = 0 \n",
    "        else:\n",
    "            all_ReWashoutfish_df['time'][i] = all_ReWashoutfish_df['time'][i-1] + diff\n",
    "    else:\n",
    "        all_ReWashoutfish_df['time'][i] = all_ReWashoutfish_df['time'][i-1] + diff\n",
    "\n",
    "# set last time value equal to second to last\n",
    "all_ReWashoutfish_df['time'].iloc[-1] = all_ReWashoutfish_df['time'].iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['distance'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['AbsYr'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['Yds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['FishV'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['FishVds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['RobotV'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['RobotVds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['distance'][i] = all_ReWashoutfish_df['distance'][i-1] + distancestep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:38: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.0018970670148830216' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReWashoutfish_df['distance'][i] = all_ReWashoutfish_df['distance'][i-1] + distancestep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['AbsYr'][i] = all_ReWashoutfish_df['AbsYr'][i-1] + AbsYrstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:39: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.00423431396484' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReWashoutfish_df['AbsYr'][i] = all_ReWashoutfish_df['AbsYr'][i-1] + AbsYrstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['Yds'][i] = all_ReWashoutfish_df['Yds'][i-1] + Ydsstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-8.032777353356512e-06' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReWashoutfish_df['Yds'][i] = all_ReWashoutfish_df['Yds'][i-1] + Ydsstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['FishV'][i] =  FishVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '121.82744657663604' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReWashoutfish_df['FishV'][i] =  FishVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['FishVds'][i] =  FishVstepds\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.23111483040795971' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReWashoutfish_df['FishVds'][i] =  FishVstepds\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['RobotV'][i] = all_ReWashoutfish_df['RobotV'][i-1] + RobotVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:43: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-1.6432499228821706' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReWashoutfish_df['RobotV'][i] = all_ReWashoutfish_df['RobotV'][i-1] + RobotVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReWashoutfish_df['RobotVds'][i] = all_ReWashoutfish_df['RobotVds'][i-1] + RobotVstepds\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\3160922666.py:44: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-0.003117355225908835' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReWashoutfish_df['RobotVds'][i] = all_ReWashoutfish_df['RobotVds'][i-1] + RobotVstepds\n"
     ]
    }
   ],
   "source": [
    "# create  column, calculate the real distance of robot of each experiment\n",
    "all_ReWashoutfish_df['distance'] = 0  # initialize distance column with 0\n",
    "all_ReWashoutfish_df['distance'][0] = 0\n",
    "all_ReWashoutfish_df['AbsYr'] = 0  # initialize distance column with 0\n",
    "all_ReWashoutfish_df['AbsYr'][0] = 0\n",
    "all_ReWashoutfish_df['Yds'] = 0  # initialize distance column with 0\n",
    "all_ReWashoutfish_df['Yds'][0] = 0\n",
    "all_ReWashoutfish_df['FishV'] = 0  # initialize distance column with 0\n",
    "all_ReWashoutfish_df['FishV'][0] = 0\n",
    "all_ReWashoutfish_df['FishVds'] = 0  # initialize distance column with 0\n",
    "all_ReWashoutfish_df['FishVds'][0] = 0\n",
    "all_ReWashoutfish_df['RobotV'] = 0  # initialize distance column with 0\n",
    "all_ReWashoutfish_df['RobotV'][0] = 0\n",
    "all_ReWashoutfish_df['RobotVds'] = 0  # initialize distance column with 0\n",
    "all_ReWashoutfish_df['RobotVds'][0] = 0\n",
    "\n",
    "for i in range(1, len(all_ReWashoutfish_df)):\n",
    "    distancestep = math.sqrt((all_ReWashoutfish_df['Xr'][i] - all_ReWashoutfish_df['Xr'][i-1])**2 + (all_ReWashoutfish_df['Yr'][i] - all_ReWashoutfish_df['Yr'][i-1])**2)\n",
    "    AbsYrstep = np.abs(all_ReWashoutfish_df['Yr'][i])\n",
    "    Ydsstep = (all_ReWashoutfish_df['Yr'][i])*distancestep\n",
    "    FishVstep = all_ReWashoutfish_df['YAWf'][i]* 180 / np.pi + 180\n",
    "    FishVstepds = (all_ReWashoutfish_df['YAWf'][i]* 180 / np.pi + 180)*distancestep\n",
    "    RobotVstep = math.atan2(( all_ReWashoutfish_df['Yr'][i] - all_ReWashoutfish_df['Yr'][i-1]),(all_ReWashoutfish_df['Xr'][i] - all_ReWashoutfish_df['Xr'][i-1]))\n",
    "    RobotVstepds = RobotVstep*distancestep\n",
    "\n",
    "    if all_ReWashoutfish_df['time'][i] == 0:\n",
    "        all_ReWashoutfish_df['distance'][i] = 0\n",
    "        all_ReWashoutfish_df['AbsYr'][i]=0\n",
    "        all_ReWashoutfish_df['Yds'][i]=0\n",
    "        all_ReWashoutfish_df['FishV'][i] = 0\n",
    "        all_ReWashoutfish_df['FishVds'][i] = 0\n",
    "        all_ReWashoutfish_df['RobotV'][i] = 0\n",
    "        all_ReWashoutfish_df['RobotVds'][i] = 0       \n",
    "        \n",
    "\n",
    "        \n",
    "    else:\n",
    "        all_ReWashoutfish_df['distance'][i] = all_ReWashoutfish_df['distance'][i-1] + distancestep\n",
    "        all_ReWashoutfish_df['AbsYr'][i] = all_ReWashoutfish_df['AbsYr'][i-1] + AbsYrstep\n",
    "        all_ReWashoutfish_df['Yds'][i] = all_ReWashoutfish_df['Yds'][i-1] + Ydsstep\n",
    "        all_ReWashoutfish_df['FishV'][i] =  FishVstep\n",
    "        all_ReWashoutfish_df['FishVds'][i] =  FishVstepds\n",
    "        all_ReWashoutfish_df['RobotV'][i] = all_ReWashoutfish_df['RobotV'][i-1] + RobotVstep\n",
    "        all_ReWashoutfish_df['RobotVds'][i] = all_ReWashoutfish_df['RobotVds'][i-1] + RobotVstepds      \n",
    "\n",
    "\n",
    "# set last time value equal to second to last\n",
    "all_ReWashoutfish_df['time'].iloc[-1] = all_ReWashoutfish_df['time'].iloc[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ReWashoutfish_df = all_ReWashoutfish_df.sort_values(by=['fish_id', 'date', 'trial_id'])\n",
    "\n",
    "# Reset the index of the grouped DataFrame\n",
    "all_ReWashoutfish_df.reset_index(inplace=True)\n",
    "\n",
    "# Define the path to the CSV file to store the all_fish_df\n",
    "all_ReWashoutfish_td_path = os.path.join(ReWashout_new_df_dir, \"all_ReWashouttd_df.csv\")\n",
    "# Save the all_fish_df to the CSV file\n",
    "all_ReWashoutfish_df.to_csv(all_ReWashoutfish_td_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "all_ReWashoutfish_df['date'] = pd.to_datetime(all_ReWashoutfish_df['date'])\n",
    "\n",
    "# Create a boolean mask to identify the rows where df['time'] = 0 for the next row\n",
    "mask = (all_ReWashoutfish_df['time'].shift(-1) == 0)\n",
    "\n",
    "\n",
    "\n",
    "# Filter the DataFrame to keep only the last rows of each trial\n",
    "filtered_all_ReWashoutfish_df = all_ReWashoutfish_df[mask]\n",
    "\n",
    "# Initialize lists to store the calculated 'distance' and absolute maximum 'Yr' values\n",
    "distance_values = []\n",
    "abs_max_yr_values = []\n",
    "trial_id_values= []\n",
    "#FishAngle_values= []\n",
    "\n",
    "\n",
    "# Loop through the filtered DataFrame and compute the 'distance' and absolute maximum 'Yr' values\n",
    "for index, row in filtered_all_ReWashoutfish_df.iterrows():\n",
    "    experiment_id = row['experiment_id']\n",
    "    trial_df = filtered_all_ReWashoutfish_df [filtered_all_ReWashoutfish_df ['experiment_id'] == experiment_id]\n",
    "    distance_values.append(trial_df.iloc[-1]['distance'])\n",
    "    trial_id_values.append(trial_df['trial_id'])\n",
    "    abs_max_yr_values.append(trial_df['Yr'].abs().max())\n",
    "  #  FishAngle_values.append(trial_df[''])\n",
    "# Create a new DataFrame with the required columns\n",
    "ReWashout_trial_new_df = pd.DataFrame({\n",
    "    'fish_id': filtered_all_ReWashoutfish_df['fish_id'],\n",
    "    'date': filtered_all_ReWashoutfish_df['date'],\n",
    "    'time': filtered_all_ReWashoutfish_df['time'],\n",
    "    'Xr':filtered_all_ReWashoutfish_df['Xr'],\n",
    "    'Yr':filtered_all_ReWashoutfish_df['Yr'],\n",
    "    'experiment_id': filtered_all_ReWashoutfish_df['experiment_id'],\n",
    "    'trialinterval':filtered_all_ReWashoutfish_df['trial_id'],\n",
    "    'distance': distance_values,\n",
    "    'AbsMax_Yr': abs_max_yr_values,\n",
    "    'AbsYr_sum':filtered_all_ReWashoutfish_df['AbsYr'],\n",
    "    'Yds_sum':filtered_all_ReWashoutfish_df['Yds'],\n",
    "    'FishV_sum':filtered_all_ReWashoutfish_df['FishV'],\n",
    "    'FishVds_sum':filtered_all_ReWashoutfish_df['FishVds'],\n",
    "    'RobotV_sum':filtered_all_ReWashoutfish_df['RobotV'],\n",
    "    'RobotVds_sum':filtered_all_ReWashoutfish_df['RobotVds'],\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by 'fish_id' and 'date'\n",
    "ReWashout_trial_new_df.sort_values(by=['fish_id', 'date'], inplace=True)\n",
    "\n",
    "# Calculate the 'Day' column based on the date difference\n",
    "ReWashout_trial_new_df['Day'] = (ReWashout_trial_new_df['date'] - ReWashout_trial_new_df.groupby('fish_id')['date'].transform('first')).dt.days + 1\n",
    "\n",
    "# Add a new column 'Day' to represent the date as a number from 1 to the end for each fish\n",
    "ReWashout_trial_new_df['Trialday'] = ReWashout_trial_new_df.groupby('fish_id')['date'].rank(method='dense').astype(int)\n",
    "\n",
    "\n",
    "def calculate_success(row):\n",
    "    if row['Xr'] < rect_pos[0]+rect_width and criterion_Yr*(-1)< row['Yr'] < criterion_Yr:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def calculate_excellent(row):\n",
    "    if row['success'] == 1 and row['distance'] < criterion_dis:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "# Apply the function to create the 'success' column\n",
    "ReWashout_trial_new_df['success'] = ReWashout_trial_new_df.apply(calculate_success, axis=1)\n",
    "ReWashout_trial_new_df['excellent'] = ReWashout_trial_new_df.apply(calculate_excellent, axis=1)\n",
    "\n",
    "\n",
    "ReWashout_trial_path = r'D:\\FOV2\\BRWanalysis\\data\\ReWashout\\all_ReWashouteachtrial.csv'\n",
    "ReWashout_trial_new_df = ReWashout_trial_new_df.reset_index(drop=True)\n",
    "ReWashout_trial_new_df.to_csv(ReWashout_trial_path, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReWashout_trial_new_df['date'] = ReWashout_trial_new_df['date'].fillna('')\n",
    "ReWashout_trial_new_df['date'] = ReWashout_trial_new_df['date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "ReWashout_sucedisday = 0\n",
    "ReWashout_sucmaxAbsyday = 0\n",
    "ReWashout_sucAbsYr_sumday = 0\n",
    "ReWashout_sucYds_sumday = 0\n",
    "ReWashout_sucFV_sumday = 0\n",
    "ReWashout_sucFVds_sumday = 0\n",
    "prev_date = None\n",
    "\n",
    "# Lists to store cumulative values\n",
    "ReWashout_cumulative_distances = []\n",
    "ReWashout_cumulative_maxAbsy = []\n",
    "ReWashout_cumulative_AbsYr_sum = []\n",
    "ReWashout_cumulative_Yds_sum = []\n",
    "ReWashout_cumulative_sucFV_sum = []\n",
    "ReWashout_cumulative_sucFVds_sum = []\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i in range(len(ReWashout_trial_new_df)):\n",
    "    if ReWashout_trial_new_df['date'][i] != prev_date:\n",
    "        # Date has changed, reset daily cumulative variables\n",
    "        ReWashout_sucedisday = 0\n",
    "        ReWashout_sucmaxAbsyday = 0\n",
    "        ReWashout_sucAbsYr_sumday = 0\n",
    "        ReWashout_sucYds_sumday = 0\n",
    "        ReWashout_sucFV_sumday = 0\n",
    "        ReWashout_sucFVds_sumday = 0\n",
    "\n",
    "    if ReWashout_trial_new_df['success'][i] == 1:\n",
    "        ReWashout_sucedisday_step = ReWashout_trial_new_df['distance'][i]\n",
    "        ReWashout_sucmaxAbsyday_step = ReWashout_trial_new_df['AbsMax_Yr'][i]\n",
    "        ReWashout_sucAbsYr_sumday_step = ReWashout_trial_new_df['AbsYr_sum'][i]\n",
    "        ReWashout_sucYds_sumday_step = ReWashout_trial_new_df['Yds_sum'][i]\n",
    "        ReWashout_sucFV_sumday_step = ReWashout_trial_new_df['FishV_sum'][i]\n",
    "        ReWashout_sucFVds_sumday_step = ReWashout_trial_new_df['FishVds_sum'][i]\n",
    "        ReWashout_sucedisday += ReWashout_sucedisday_step\n",
    "        ReWashout_sucmaxAbsyday += ReWashout_sucmaxAbsyday_step\n",
    "        ReWashout_sucAbsYr_sumday += ReWashout_sucAbsYr_sumday_step\n",
    "        ReWashout_sucYds_sumday += ReWashout_sucYds_sumday_step\n",
    "        ReWashout_sucFV_sumday += ReWashout_sucFV_sumday_step\n",
    "        ReWashout_sucFVds_sumday += ReWashout_sucFVds_sumday_step\n",
    "    else:\n",
    "        ReWashout_sucedisday_step = 0\n",
    "        ReWashout_sucmaxAbsyday_step = 0\n",
    "        ReWashout_sucAbsYr_sumday_step = 0\n",
    "        ReWashout_sucYds_sumday_step = 0\n",
    "        ReWashout_sucFV_sumday_step = 0\n",
    "        ReWashout_sucFVds_sumday_step = 0\n",
    "        ReWashout_sucmaxAbsyday += ReWashout_sucmaxAbsyday_step\n",
    "        ReWashout_sucAbsYr_sumday += ReWashout_sucAbsYr_sumday_step\n",
    "        ReWashout_sucYds_sumday += ReWashout_sucYds_sumday_step\n",
    "        ReWashout_sucFV_sumday += ReWashout_sucFV_sumday_step\n",
    "        ReWashout_sucFVds_sumday += ReWashout_sucFVds_sumday_step\n",
    "\n",
    "    # Append cumulative values\n",
    "    ReWashout_cumulative_distances.append(ReWashout_sucedisday)\n",
    "    ReWashout_cumulative_maxAbsy.append(ReWashout_sucmaxAbsyday)\n",
    "    ReWashout_cumulative_AbsYr_sum.append(ReWashout_sucAbsYr_sumday)\n",
    "    ReWashout_cumulative_Yds_sum.append(ReWashout_sucYds_sumday)\n",
    "    ReWashout_cumulative_sucFV_sum.append(ReWashout_sucFV_sumday)\n",
    "    ReWashout_cumulative_sucFVds_sum.append(ReWashout_sucFVds_sumday)\n",
    "\n",
    "    prev_date = ReWashout_trial_new_df['date'][i]\n",
    "\n",
    "# Add the cumulative columns to the DataFrame\n",
    "ReWashout_trial_new_df['cumulative_success_distance'] = ReWashout_cumulative_distances\n",
    "ReWashout_trial_new_df['cumulative_success_maxAbsy'] = ReWashout_cumulative_maxAbsy\n",
    "ReWashout_trial_new_df['cumulative_success_AbsYr_sum'] = ReWashout_cumulative_AbsYr_sum\n",
    "ReWashout_trial_new_df['cumulative_success_Yds_sum'] = ReWashout_cumulative_Yds_sum\n",
    "ReWashout_trial_new_df['cumulative_success_sucFV_sum'] = ReWashout_cumulative_sucFV_sum\n",
    "ReWashout_trial_new_df['cumulative_success_sucFVds_sum'] = ReWashout_cumulative_sucFVds_sum\n",
    "\n",
    "# Group the original table by ['fish_id', 'date'] and calculate the average values for ['time'], ['distance'], and ['AbsMax_Yr']\n",
    "ReWashout_grouped_data = ReWashout_trial_new_df.groupby(['fish_id', 'date', 'Day', 'Trialday']).agg({'time': 'mean', 'distance': 'mean', 'AbsMax_Yr': 'mean', 'AbsYr_sum': 'mean', 'Yds_sum': 'mean', 'FishV_sum': 'mean', 'FishVds_sum': 'mean', 'success': 'mean', 'excellent': 'mean'})\n",
    "\n",
    "# Reset the index of the grouped DataFrame\n",
    "ReWashout_grouped_data.reset_index(inplace=True)\n",
    "\n",
    "# Calculate the time of success and the time of excellent\n",
    "Wsum_data = ReWashout_trial_new_df.groupby(['fish_id', 'date', 'Day', 'Trialday'])[['success', 'excellent']].sum().reset_index()\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "ReWashout_new_table = pd.DataFrame({\n",
    "    'fish_id': ReWashout_grouped_data['fish_id'],\n",
    "    'date': ReWashout_grouped_data['date'],\n",
    "    'Day': ReWashout_grouped_data['Day'],\n",
    "    'Trialday': ReWashout_grouped_data['Trialday'],\n",
    "    'average time': ReWashout_grouped_data['time'],\n",
    "    'average distance': ReWashout_grouped_data['distance'],\n",
    "    'average maximum deviation': ReWashout_grouped_data['AbsMax_Yr'],\n",
    "    'average AbsYr_sum': ReWashout_grouped_data['AbsYr_sum'],\n",
    "    'average Yds_sum': ReWashout_grouped_data['Yds_sum'],\n",
    "    'average FishV_sum': ReWashout_grouped_data['FishV_sum'],\n",
    "    'average FishVds_sum': ReWashout_grouped_data['FishVds_sum'],\n",
    "    'average success rate': ReWashout_grouped_data['success'],\n",
    "    'average excellent rate': ReWashout_grouped_data['excellent'],\n",
    "    'timeofsuc': Wsum_data['success'],\n",
    "    'timeofexc': Wsum_data['excellent'],\n",
    "})\n",
    "\n",
    "ReWashout_trial_new_df.to_csv(ReWashout_trial_path, index=False)\n",
    "ReWashout_session_path = r'D:\\FOV2\\BRWanalysis\\data\\ReWashout\\all_ReWashoutsession.csv'\n",
    "ReWashout_new_table.to_csv(ReWashout_session_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\2473162730.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ReWrows_before_date_change.loc[i, 'average_success_distance'] = ReWrows_before_date_change.loc[i, 'cumulative_success_distance'] / ReWashout_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\2473162730.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ReWrows_before_date_change.loc[i, 'average_success_maxAbsy'] = ReWrows_before_date_change.loc[i, 'cumulative_success_maxAbsy'] / ReWashout_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\2473162730.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ReWrows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = ReWrows_before_date_change.loc[i, 'cumulative_success_AbsYr_sum'] / ReWashout_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\2473162730.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ReWrows_before_date_change.loc[i, 'average_success_Yds_sum'] = ReWrows_before_date_change.loc[i, 'cumulative_success_Yds_sum'] / ReWashout_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\2473162730.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ReWrows_before_date_change.loc[i, 'average_success_FV_sum'] = ReWrows_before_date_change.loc[i, 'cumulative_success_sucFV_sum'] / ReWashout_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_47400\\2473162730.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ReWrows_before_date_change.loc[i, 'average_success_FVds_sum'] = ReWrows_before_date_change.loc[i, 'cumulative_success_sucFVds_sum'] / ReWashout_new_table.loc[i, 'timeofsuc']\n"
     ]
    }
   ],
   "source": [
    "# Create a mask to identify the rows where 'date' changes\n",
    "ReWdate_change_mask = ReWashout_trial_new_df['date'] != ReWashout_trial_new_df['date'].shift(-1)\n",
    "\n",
    "# Use the mask to extract the rows before the date changes\n",
    "ReWrows_before_date_change = ReWashout_trial_new_df[ReWdate_change_mask]\n",
    "\n",
    "# Reset the index of rows_before_date_change and summary DataFrames\n",
    "ReWrows_before_date_change.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(len(ReWrows_before_date_change)):\n",
    "    if ReWashout_new_table.loc[i, 'timeofsuc'] != 0:\n",
    "        ReWrows_before_date_change.loc[i, 'average_success_distance'] = ReWrows_before_date_change.loc[i, 'cumulative_success_distance'] / ReWashout_new_table.loc[i, 'timeofsuc']\n",
    "        ReWrows_before_date_change.loc[i, 'average_success_maxAbsy'] = ReWrows_before_date_change.loc[i, 'cumulative_success_maxAbsy'] / ReWashout_new_table.loc[i, 'timeofsuc']\n",
    "        ReWrows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = ReWrows_before_date_change.loc[i, 'cumulative_success_AbsYr_sum'] / ReWashout_new_table.loc[i, 'timeofsuc']\n",
    "        ReWrows_before_date_change.loc[i, 'average_success_Yds_sum'] = ReWrows_before_date_change.loc[i, 'cumulative_success_Yds_sum'] / ReWashout_new_table.loc[i, 'timeofsuc']\n",
    "        ReWrows_before_date_change.loc[i, 'average_success_FV_sum'] = ReWrows_before_date_change.loc[i, 'cumulative_success_sucFV_sum'] / ReWashout_new_table.loc[i, 'timeofsuc']\n",
    "        ReWrows_before_date_change.loc[i, 'average_success_FVds_sum'] = ReWrows_before_date_change.loc[i, 'cumulative_success_sucFVds_sum'] / ReWashout_new_table.loc[i, 'timeofsuc']\n",
    "    else:\n",
    "        ReWrows_before_date_change.loc[i, 'average_success_distance'] = 0\n",
    "        ReWrows_before_date_change.loc[i, 'average_success_maxAbsy'] = 0\n",
    "        ReWrows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = 0\n",
    "        ReWrows_before_date_change.loc[i, 'average_success_Yds_sum'] = 0\n",
    "        ReWrows_before_date_change.loc[i, 'average_success_FV_sum'] = 0\n",
    "        ReWrows_before_date_change.loc[i, 'average_success_FVds_sum'] = 0\n",
    "\n",
    "ReWrows_before_date_change = ReWrows_before_date_change.reset_index()\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "ReWashout_new_table = pd.DataFrame({\n",
    "    'fish_id': ReWashout_grouped_data['fish_id'],\n",
    "    'date': ReWashout_grouped_data['date'],\n",
    "    'Day': ReWashout_grouped_data['Day'],\n",
    "    'Trialday': ReWashout_grouped_data['Trialday'],\n",
    "    'average time': ReWashout_grouped_data['time'],\n",
    "    'average distance': ReWashout_grouped_data['distance'],\n",
    "    'average distance': ReWashout_grouped_data['distance'],\n",
    "    'average maximum deviation': ReWashout_grouped_data['AbsMax_Yr'],\n",
    "    'average AbsYr_sum': ReWashout_grouped_data['AbsYr_sum'],\n",
    "    'average Yds_sum': ReWashout_grouped_data['Yds_sum'],\n",
    "    'average FishV_sum': ReWashout_grouped_data['FishV_sum'],\n",
    "    'average FishVds_sum': ReWashout_grouped_data['FishVds_sum'],\n",
    "    'average success rate': ReWashout_grouped_data['success'],\n",
    "    'average excellent rate': ReWashout_grouped_data['excellent'],\n",
    "    'timeofsuc': Wsum_data['success'],\n",
    "    'timeofexc': Wsum_data['excellent'],\n",
    "    'average_success_distance': ReWrows_before_date_change['average_success_distance'],\n",
    "    'average_success_maxAbsy': ReWrows_before_date_change['average_success_maxAbsy'],\n",
    "    'average_success_AbsYr_sum': ReWrows_before_date_change['average_success_AbsYr_sum'],\n",
    "    'average_success_Yds_sum': ReWrows_before_date_change['average_success_Yds_sum'],\n",
    "    'average_success_FV_sum': ReWrows_before_date_change['average_success_FV_sum'],\n",
    "    'average_success_FVds_sum': ReWrows_before_date_change['average_success_FVds_sum']\n",
    "})\n",
    "\n",
    "ReWashout_trial_new_df.to_csv(ReWashout_trial_path, index=True)\n",
    "\n",
    "ReWashout_new_table.to_csv(ReWashout_session_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReWashoutdata_dir = \"D:/FOV2/ReWashoutdata/\"\n",
    "ReWashoutstore_dir = \"D:/FOV2/BRWanalysis/data/ReWashout/\"\n",
    "ReWashoutplot_dir = \"D:/FOV2/BRWanalysis/plot/ReWashout/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfish_ReW_point_df_path = os.path.join(ReWashoutstore_dir,'new_df/all_ReWashouttd_df.csv')\n",
    "\n",
    "\n",
    "allfish_ReW_session_df_path = os.path.join(ReWashoutstore_dir,'all_ReWashoutsession.csv')\n",
    "\n",
    "allfish_ReW_trial_df_path = os.path.join(ReWashoutstore_dir,'all_ReWashouteachtrial.csv')\n",
    "\n",
    "allfish_ReW_point_df = pd.read_csv(allfish_ReW_point_df_path)\n",
    "\n",
    "allfish_ReW_trial_df = pd.read_csv(allfish_ReW_trial_df_path)\n",
    "\n",
    "allfish_ReW_session_df = pd.read_csv(allfish_ReW_session_df_path)\n",
    "\n",
    "unique_ReW_fish = allfish_ReW_session_df['fish_id'].unique()\n",
    "unique_ReW_dates = allfish_ReW_session_df['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_ReWarrow_plot(fish_id, date, trials):\n",
    "    # Create a new figure and axes objects for the subplot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Initialize a list to store Line2D objects for the legend\n",
    "    legend_lines = []\n",
    "    legend_labels = []\n",
    "    \n",
    "    # Loop over each experiment for the current date and fish\n",
    "    for exp_id, experiment in enumerate(trials):\n",
    "        # Filter the DataFrame for the current experiment\n",
    "        exp_df = allfish_ReW_trial_df[(allfish_ReW_trial_df['date'] == date) & (allfish_ReW_trial_df['fish_id'] == fish_id) & (allfish_ReW_trial_df['experiment_id'] == experiment)]\n",
    "        \n",
    "        # Get the X and Y values for the experiment\n",
    "        X = exp_df['Xr'].values\n",
    "        Y = exp_df['Yr'].values\n",
    "        \n",
    "        # Determine the line color based on exp_id\n",
    "        line_color = plt.cm.winter(exp_id / len(trials))\n",
    "        \n",
    "        # Plot arrows and add labels for each trial\n",
    "        for x, y in zip(X, Y):\n",
    "            ax.arrow(0, 0, x, y, head_width=0.05, head_length=0.1, fc=line_color, ec=line_color)\n",
    "            ax.text(x, y, f\"{math.degrees(math.atan2(y, x)):.2f}\", fontsize=8, ha='right') \n",
    "\n",
    "        # Add legend information\n",
    "        line = plt.Line2D([0], [0], color=line_color, label=f'Experiment {experiment}')\n",
    "        legend_lines.append(line)\n",
    "        legend_labels.append(f'Trial {exp_id + 1}')\n",
    "                # Define the vertices of the hexagon in (x,y) coordinate pairs\n",
    "\n",
    "      \n",
    "        # Define the target area position, width, and height\n",
    "        rect_pos = (-2.2, -0.314)\n",
    "        rect_width = 0.35\n",
    "        rect_height = 0.628\n",
    "\n",
    "        # Create a rectangle patch with the specified properties\n",
    "        rect = patches.Rectangle(rect_pos, rect_width, rect_height, linewidth=2, edgecolor='r', facecolor='none', alpha=0.5)\n",
    "        # Create a polygon patch with the specified vertices\n",
    "        hexagon = patches.Polygon(vertices, linewidth=2, edgecolor='r', facecolor='none', alpha=0.5)\n",
    "        # Add the polygon patch to the subplot\n",
    "        ax.add_patch(hexagon)\n",
    "        # Add the rectangle patch to the subplot\n",
    "        ax.add_patch(rect)\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "    # Set aspect ratio of the plot to be equal\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # Add a title to the subplot\n",
    "    ax.set_title(f'{fish_id} - Date {date} - Arrow Plot')\n",
    "\n",
    "    # Add legend to the subplot\n",
    "    ax.legend(legend_lines, legend_labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    # Set fixed data ranges for both axes\n",
    "    plt.xlim(x_range)\n",
    "    plt.ylim(y_range)\n",
    "    # Save the plot with a custom filename\n",
    "    plt.savefig(f'D:\\\\FOV2\\\\BRWanalysis\\\\plots\\\\ReWashout\\\\{fish_id}\\\\{date}_{fish_id}_arrow_plot.png')\n",
    "    \n",
    "    # Close the current figure to avoid overlapping plots\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ReWpoint_plot(fish_id, date, trials):\n",
    "    # Create a new figure and axes objects for the subplot\n",
    "    fig, ax = plt.subplots(figsize=(2.3, 2.3))\n",
    "    \n",
    "    # Initialize a list to store Line2D objects for the legend\n",
    "    legend_lines = []\n",
    "    legend_labels = []\n",
    "    \n",
    "    # Loop over each experiment for the current date and fish\n",
    "    for exp_id, experiment in enumerate(trials):\n",
    "        # Filter the DataFrame for the current experiment\n",
    "        exp_df = allfish_ReW_point_df[(allfish_ReW_point_df['date'] == date) & (allfish_ReW_point_df['fish_id'] == fish_id) & (allfish_ReW_point_df['experiment_id'] == experiment)]\n",
    "        \n",
    "        # Get the X and Y values for the experiment\n",
    "        X = exp_df['Xr'].values\n",
    "        Y = exp_df['Yr'].values\n",
    "        # Determine the line color based on exp_id\n",
    "        #line_color = plt.cm.jet(exp_id / len(experiments))  # You can use a different colormap if needed\n",
    "        line_color = plt.cm.winter(exp_id / len(trials))\n",
    "\n",
    "        \n",
    "        # Plot the experiment on the subplot and store the Line2D object in the list\n",
    "        line, = ax.plot(X, Y, label=f'Trial {exp_id + 1}', color=line_color)\n",
    "        \n",
    "        ax.scatter(X[0], Y[0], color='#F0E442', s=30)  # Start point is green\n",
    "        ax.scatter(X[-1], Y[-1], color='#CC79A7', s=30)  # End point is red\n",
    "        legend_lines.append(line)\n",
    "        legend_labels.append(f'Trial {exp_id + 1}')\n",
    "\n",
    "        # Define the vertices of the hexagon in (x,y) coordinate pairs\n",
    "\n",
    "      \n",
    "        # Define the target area position, width, and height\n",
    "        rect_pos = (-2.2, -0.314)\n",
    "        rect_width = 0.35\n",
    "        rect_height = 0.628\n",
    "\n",
    "        # Create a rectangle patch with the specified properties\n",
    "        rect = patches.Rectangle(rect_pos, rect_width, rect_height, linewidth=2, edgecolor='#CC79A7', facecolor='none', alpha=0.5)\n",
    "        # Create a polygon patch with the specified vertices\n",
    "        hexagon = patches.Polygon(vertices, linewidth=2, edgecolor='black', facecolor='none', alpha=0.5)\n",
    "               # Add the polygon patch to the subplot\n",
    "        ax.add_patch(hexagon)\n",
    "        # Add the rectangle patch to the subplot\n",
    "        ax.add_patch(rect)\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "    # # Add a title to the subplot\n",
    "    # ax.set_title(f'{fish_id} - Date {date} - Washout')\n",
    "    # Set fixed data ranges for both axes\n",
    "    plt.xlim(x_range)\n",
    "    plt.ylim(y_range)\n",
    "\n",
    "    # # Add a legend to the subplot\n",
    "    # ax.legend(legend_lines, legend_labels)\n",
    "    # Add legend to the subplot\n",
    "    # ax.legend(legend_lines, legend_labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.grid(False)\n",
    "    # Save the plot with a custom filename\n",
    "    plt.savefig(f'D:\\\\FOV2\\\\BRWanalysis\\\\plots\\\\ReWashout\\\\{fish_id}\\\\{date}_{fish_id}_ReWashout.png',  bbox_inches='tight',dpi=600)\n",
    "    \n",
    "    # Close the current figure to avoid overlapping plots\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fish_id in unique_ReW_fish:\n",
    "    \n",
    "    for date in unique_ReW_dates:\n",
    "    #for date in ['2023-10-04']:\n",
    "        # Filter the DataFrame for the current fish and date\n",
    "        trials = allfish_ReW_point_df[(allfish_ReW_point_df['fish_id'] == fish_id) & (allfish_ReW_point_df['date'] == date)]['experiment_id'].unique()\n",
    "        \n",
    "        if len(trials) > 0:\n",
    "            create_ReWpoint_plot(fish_id, date, trials)\n",
    "            # create_ReWarrow_plot(fish_id, date, trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coolplots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
