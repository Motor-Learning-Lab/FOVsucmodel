{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import opinionated\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "#plt.style.use(\"opinionated_rc\")\n",
    "import colormaps as cmaps \n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.patches import Rectangle, FancyArrowPatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input some set up\n",
    "#target point(-2.85,0.108).position point(-2.85,-0.623),width0.71,height1.256,and the rader postion0.45,\n",
    "# Define the target point\n",
    "target_x = -2\n",
    "rader_x = 0.45\n",
    "target_y = 0\n",
    "\n",
    " # Define the vertices of the hexagon in (x,y) coordinate pairs\n",
    "#vertices = [(-2.0035, -1.27), (-2.0035, 1.486), (-0.8405,  1.486), (-0.8405, 1.123), (0.8465, 1.123), (0.8465, -1.270)]\n",
    "vertices = [(-2.5, -1.37), (-2.5, 1.486), (-0.04,  1.486), (-0.04, 1.123), (0.8465, 1.123), (0.8465, -1.37)]\n",
    "# Define the target area position, width, and height.target point(-2.85,0.108).position point(-2.85,-0.623),width0.71,height1.256,and the rader postion error 0.32\n",
    "rect_pos = (-2.2,-0.314 )\n",
    "rect_width = 0.35\n",
    "rect_height = 0.628\n",
    "\n",
    "criterion_dis = 4\n",
    "criterion_Yr = 0.314\n",
    "\n",
    "x_range = (-2.8,1.8)\n",
    "y_range = (-1.8,1.8)\n",
    "time_range = (0,180)\n",
    "Y_range = (0,0.5)\n",
    "\n",
    "# Define the path to the directory containing the data, the path to store the output \n",
    "Baselinedata_dir = \"D:/FOV2/Baselinedata/\"\n",
    "Baselinestore_dir = \"D:/FOV2/BRWanalysis/data/Baseline/\"\n",
    "\n",
    "Rotationdata_dir = \"D:/FOV2/Rotationdata/\"\n",
    "Rotationstore_dir = \"D:/FOV2/BRWanalysis/data/Rotation/\"\n",
    "\n",
    "Washoutdata_dir = \"D:/FOV2/Washoutdata/\"\n",
    "Washoutstore_dir = \"D:/FOV2/BRWanalysis/data/Washout/\"\n",
    "\n",
    "\n",
    "ReRotationdata_dir = \"D:/FOV2/ReRotationdata/\"\n",
    "ReRotationstore_dir = \"D:/FOV2/BRWanalysis/data/ReRotaion/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rawdata address declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the directory to store the new_df\n",
    "Baseline_new_df_dir = os.path.join(\"D:/FOV2/BRWanalysis/data/Baseline/new_df/\")\n",
    "Rotation_new_df_dir = os.path.join(\"D:/FOV2/BRWanalysis/data/Rotation/new_df/\")\n",
    "Washout_new_df_dir = os.path.join(\"D:/FOV2/BRWanalysis/data/Washout/new_df/\")\n",
    "ReRotation_new_df_dir = os.path.join(\"D:/FOV2/BRWanalysis/data/ReRotation/new_df/\")\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(Baseline_new_df_dir):\n",
    "    os.makedirs(Baseline_new_df_dir)\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(Rotation_new_df_dir):\n",
    "    os.makedirs(Rotation_new_df_dir)\n",
    " # Create the directory if it does not exist\n",
    "if not os.path.exists(Washout_new_df_dir):\n",
    "    os.makedirs(Washout_new_df_dir)\n",
    "if not os.path.exists(ReRotation_new_df_dir):\n",
    "    os.makedirs(ReRotation_new_df_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All valid data points for each fish in the washout session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the fish IDs in Washout session\n",
    "for fish_id in ['fish7','fish3','fish9','fish10','fish12','fish14']:\n",
    "    # Create an empty list to store the data frames\n",
    "    dfs = []\n",
    "\n",
    "    # Loop over the directories in the data directory\n",
    "    for dir_name in os.listdir(Washoutdata_dir):\n",
    "        # Set the path to the directory\n",
    "        dir_path = os.path.join(Washoutdata_dir, dir_name, fish_id)\n",
    "        # Check if the directory exists\n",
    "        if os.path.isdir(dir_path):\n",
    "            # Loop over the CSV files in the directory\n",
    "            for file_name in os.listdir(dir_path):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    # Set the path to the CSV file\n",
    "                    file_path = os.path.join(dir_path, file_name)\n",
    "                    # Load the CSV file into a DataFrame\n",
    "                    df = pd.read_csv(file_path)\n",
    "\n",
    "                    # Add the date and file name columns\n",
    "                    df[\"date\"] = dir_name\n",
    "                    df[\"experiment_id\"] = file_name.split(\".\")[0]\n",
    "                    df[\"fish_id\"] = fish_id\n",
    "                    df['trial_id'] = file_name.split('__')[-1].split('.')[0]\n",
    "                    # Append the DataFrame to the list\n",
    "                    dfs.append(df)\n",
    "\n",
    "    # Concatenate the DataFrames in the list\n",
    "    combined_df = pd.concat(dfs)\n",
    "\n",
    "    # Remove junk frames with no goldfish activity detected\n",
    "    new_df = combined_df[(combined_df[\"Xf\"] != 0) & (combined_df[\"Yf\"] != 0)]\n",
    "\n",
    "    # Set the path to the CSV file to store the new_df\n",
    "    new_df_path = os.path.join(Washout_new_df_dir, f\"{fish_id}_Washout_new_df.csv\")\n",
    "    # Save the new_df to the CSV file\n",
    "    new_df.to_csv(new_df_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All valid data points for each fish in the Rotation session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the fish IDs in Rotation session\n",
    "for fish_id in ['fish3','fish4',\"fish7\",'fish9','fish10','fish12','fish14']:\n",
    "    # Create an empty list to store the data frames\n",
    "    dfs = []\n",
    "\n",
    "    # Loop over the directories in the data directory\n",
    "    for dir_name in os.listdir(Rotationdata_dir):\n",
    "        # Set the path to the directory\n",
    "        dir_path = os.path.join(Rotationdata_dir, dir_name, fish_id)\n",
    "        # Check if the directory exists\n",
    "        if os.path.isdir(dir_path):\n",
    "            # Loop over the CSV files in the directory\n",
    "            for file_name in os.listdir(dir_path):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    # Set the path to the CSV file\n",
    "                    file_path = os.path.join(dir_path, file_name)\n",
    "                    # Load the CSV file into a DataFrame\n",
    "                    df = pd.read_csv(file_path)\n",
    "\n",
    "                    # Add the date and file name columns\n",
    "                    df[\"date\"] = dir_name\n",
    "                    df[\"experiment_id\"] = file_name.split(\".\")[0]\n",
    "                    df[\"fish_id\"] = fish_id\n",
    "                    df['trial_id'] = file_name.split('__')[-1].split('.')[0]\n",
    "                    # Append the DataFrame to the list\n",
    "                    dfs.append(df)\n",
    "\n",
    "    # Concatenate the DataFrames in the list\n",
    "    combined_df = pd.concat(dfs)\n",
    "\n",
    "    # Remove junk frames with no goldfish activity detected\n",
    "    new_df = combined_df[(combined_df[\"Xf\"] != 0) & (combined_df[\"Yf\"] != 0)]\n",
    "\n",
    "    # Set the path to the CSV file to store the new_df\n",
    "    new_df_path = os.path.join(Rotation_new_df_dir, f\"{fish_id}_Rotation_new_df.csv\")\n",
    "    # Save the new_df to the CSV file\n",
    "    new_df.to_csv(new_df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the fish IDs in ReRotation session\n",
    "for fish_id in ['fish7','fish3','fish9','fish10','fish12','fish14']:\n",
    "    # Create an empty list to store the data frames\n",
    "    dfs = []\n",
    "\n",
    "    # Loop over the directories in the data directory\n",
    "    for dir_name in os.listdir(ReRotationdata_dir):\n",
    "        # Set the path to the directory\n",
    "        dir_path = os.path.join(ReRotationdata_dir, dir_name, fish_id)\n",
    "        # Check if the directory exists\n",
    "        if os.path.isdir(dir_path):\n",
    "            # Loop over the CSV files in the directory\n",
    "            for file_name in os.listdir(dir_path):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    # Set the path to the CSV file\n",
    "                    file_path = os.path.join(dir_path, file_name)\n",
    "                    try:\n",
    "                        df = pd.read_csv(file_path)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to read {file_path}: {e}\")\n",
    "\n",
    "                    # Add the date and file name columns\n",
    "                    df[\"date\"] = dir_name\n",
    "                    df[\"experiment_id\"] = file_name.split(\".\")[0]\n",
    "                    df[\"fish_id\"] = fish_id\n",
    "                    df['trial_id'] = file_name.split('__')[-1].split('.')[0]\n",
    "                    # Append the DataFrame to the list\n",
    "                    dfs.append(df)\n",
    "\n",
    "    # Concatenate the DataFrames in the list\n",
    "    combined_df = pd.concat(dfs)\n",
    "\n",
    "    # Remove junk frames with no goldfish activity detected\n",
    "    new_df = combined_df[(combined_df[\"Xf\"] != 0) & (combined_df[\"Yf\"] != 0)]\n",
    "\n",
    "    # Set the path to the CSV file to store the new_df\n",
    "    new_df_path = os.path.join(ReRotation_new_df_dir, f\"{fish_id}_ReRotation_new_df.csv\")\n",
    "    # Save the new_df to the CSV file\n",
    "    new_df.to_csv(new_df_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All valid data points for each fish in the Baseline session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\3086274609.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(dfs)\n"
     ]
    }
   ],
   "source": [
    "# Loop over the fish IDs in Baseline session\n",
    "for fish_id in ['fish3','fish4','fish5','fish6','fish7','fish8','fish9',\"fish10\",\"fish11\",'fish12','fish14']:\n",
    "    # Create an empty list to store the data frames\n",
    "    dfs = []\n",
    "\n",
    "    # Loop over the directories in the data directory\n",
    "    for dir_name in os.listdir(Baselinedata_dir):\n",
    "        # Set the path to the directory\n",
    "        dir_path = os.path.join(Baselinedata_dir, dir_name, fish_id)\n",
    "        # Check if the directory exists\n",
    "        if os.path.isdir(dir_path):\n",
    "            # Loop over the CSV files in the directory\n",
    "            for file_name in os.listdir(dir_path):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    # Set the path to the CSV file\n",
    "                    file_path = os.path.join(dir_path, file_name)\n",
    "                    try:\n",
    "                        df = pd.read_csv(file_path)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to read {file_path}: {e}\")\n",
    "\n",
    "                    # Add the date and file name columns\n",
    "                    df[\"date\"] = dir_name\n",
    "                    df[\"experiment_id\"] = file_name.split(\".\")[0]\n",
    "                    df[\"fish_id\"] = fish_id\n",
    "                    df['trial_id'] = file_name.split('__')[-1].split('.')[0]\n",
    "                    # Append the DataFrame to the list\n",
    "                    dfs.append(df)\n",
    "\n",
    "    # Concatenate the DataFrames in the list\n",
    "    combined_df = pd.concat(dfs)\n",
    "\n",
    "    # Remove junk frames with no goldfish activity detected\n",
    "    new_df = combined_df[(combined_df[\"Xf\"] != 0) & (combined_df[\"Yf\"] != 0)]\n",
    "\n",
    "    # Set the path to the CSV file to store the new_df\n",
    "    new_df_path = os.path.join(Baseline_new_df_dir, f\"{fish_id}_Baseline_new_df.csv\")\n",
    "    # Save the new_df to the CSV file\n",
    "    new_df.to_csv(new_df_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All fish raw data in Baseline session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the DataFrames\n",
    "Baselinedfs = []\n",
    "\n",
    "# Loop over the fish IDs\n",
    "for fish_id in [\"fish3\", \"fish4\",\"fish5\", \"fish6\", \"fish7\",\"fish8\",\"fish11\",\"fish9\",\"fish10\",'fish12','fish14']:\n",
    "    # Set the path to the new_df table for the fish\n",
    "    new_df_path = os.path.join (Baseline_new_df_dir, f\"{fish_id}_Baseline_new_df.csv\")\n",
    "    # Load the new_df table into a DataFrame\n",
    "    df = pd.read_csv(new_df_path)\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    Baselinedfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames in the list\n",
    "all_Baselinefish_df = pd.concat(Baselinedfs)\n",
    "\n",
    "# Reset the DataFrame index to start from 0\n",
    "all_Baselinefish_df = all_Baselinefish_df.reset_index(drop=True)\n",
    "# Define the path to the CSV file to store the all_fish_df\n",
    "all_Baselinefish_df_path = os.path.join(Baseline_new_df_dir, \"all_Baselinefish_df.csv\")\n",
    "# Save the all_fish_df to the CSV file\n",
    "all_Baselinefish_df.to_csv(all_Baselinefish_df_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All fish raw data in Rotation session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the DataFrames\n",
    "Rotationdfs = []\n",
    "\n",
    "# Loop over the fish IDs\n",
    "for fish_id in [\"fish3\", \"fish4\",\"fish7\",'fish9','fish10','fish12','fish14']:\n",
    "    # Set the path to the new_df table for the fish\n",
    "    new_df_path = os.path.join (Rotation_new_df_dir, f\"{fish_id}_Rotation_new_df.csv\")\n",
    "    # Load the new_df table into a DataFrame\n",
    "    df = pd.read_csv(new_df_path)\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    Rotationdfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames in the list\n",
    "all_Rotationfish_df = pd.concat(Rotationdfs)\n",
    "\n",
    "# Reset the DataFrame index to start from 0\n",
    "all_Rotationfish_df = all_Rotationfish_df.reset_index(drop=True)\n",
    "# Define the path to the CSV file to store the all_fish_df\n",
    "all_Rotationfish_df_path = os.path.join(Rotation_new_df_dir, \"all_Rotationfish_df.csv\")\n",
    "# Save the all_fish_df to the CSV file\n",
    "all_Rotationfish_df.to_csv(all_Rotationfish_df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the DataFrames\n",
    "ReRotationdfs = []\n",
    "\n",
    "# Loop over the fish IDs\n",
    "for fish_id in [\"fish7\",'fish3','fish9','fish10','fish12','fish14']:\n",
    "    # Set the path to the new_df table for the fish\n",
    "    new_df_path = os.path.join(ReRotation_new_df_dir, f\"{fish_id}_ReRotation_new_df.csv\")\n",
    "    # Load the new_df table into a DataFrame\n",
    "    df = pd.read_csv(new_df_path)\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    ReRotationdfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames in the list\n",
    "all_ReRotationfish_df = pd.concat(ReRotationdfs)\n",
    "\n",
    "# Reset the DataFrame index to start from 0\n",
    "all_ReRotationfish_df = all_ReRotationfish_df.reset_index(drop=True)\n",
    "# Define the path to the CSV file to store the all_ReRotationfish_df\n",
    "all_ReRotationfish_df_path = os.path.join(ReRotation_new_df_dir, \"all_ReRotationfish_df.csv\")\n",
    "# Save the all_ReRotationfish_df to the CSV file\n",
    "all_ReRotationfish_df.to_csv(all_ReRotationfish_df_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All fish raw data in Washout session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the DataFrames\n",
    "Washoutdfs = []\n",
    "\n",
    "# Loop over the fish IDs\n",
    "for fish_id in [\"fish7\",\"fish3\",'fish9','fish10','fish12','fish14']:\n",
    "    # Set the path to the new_df table for the fish\n",
    "    new_df_path = os.path.join (Washout_new_df_dir, f\"{fish_id}_Washout_new_df.csv\")\n",
    "    # Load the new_df table into a DataFrame\n",
    "    df = pd.read_csv(new_df_path)\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    Washoutdfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames in the list\n",
    "all_Washoutfish_df = pd.concat(Washoutdfs)\n",
    "\n",
    "# Reset the DataFrame index to start from 0\n",
    "all_Washoutfish_df = all_Washoutfish_df.reset_index(drop=True)\n",
    "# Define the path to the CSV file to store the all_fish_df\n",
    "all_Washoutfish_df_path = os.path.join(Washout_new_df_dir, \"allWashoutfish_df.csv\")\n",
    "# Save the all_fish_df to the CSV file\n",
    "all_Washoutfish_df.to_csv(all_Washoutfish_df_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a trial time column for all Washout fish "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\495016434.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['time'][0] = 0  # set first time value to 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\495016434.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['time'][i] = all_Washoutfish_df['time'][i-1] + diff\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\495016434.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.06827211379999909' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Washoutfish_df['time'][i] = all_Washoutfish_df['time'][i-1] + diff\n"
     ]
    }
   ],
   "source": [
    "# create time column, calculate the real time of each experiment\n",
    "all_Washoutfish_df['time'] = 0  # initialize time column with 0\n",
    "all_Washoutfish_df['time'][0] = 0  # set first time value to 0\n",
    "\n",
    "for i in range(1, len(all_Washoutfish_df)):\n",
    "    diff = all_Washoutfish_df['t'][i] - all_Washoutfish_df['t'][i-1]\n",
    "    if diff > 1.5 or diff < 0 :\n",
    "        if all_Washoutfish_df['experiment_id'][i]!=all_Washoutfish_df['experiment_id'][i-1]:\n",
    "            all_Washoutfish_df['time'][i] = 0 \n",
    "        else:\n",
    "            all_Washoutfish_df['time'][i] = all_Washoutfish_df['time'][i-1] + diff\n",
    "    else:\n",
    "        all_Washoutfish_df['time'][i] = all_Washoutfish_df['time'][i-1] + diff\n",
    "\n",
    "# set last time value equal to second to last\n",
    "all_Washoutfish_df['time'].iloc[-1] = all_Washoutfish_df['time'].iloc[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 'the real distance of robot of each trial' column, a 'AbsYr' columnm, a 'Yds' column,a 'FishV' column, a 'FishVds' for all Washout fish "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['distance'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['AbsYr'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['Yds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['FishV'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['FishVds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['RobotV'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['RobotVds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['distance'][i] = all_Washoutfish_df['distance'][i-1] + distancestep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:38: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.0036964967642850307' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Washoutfish_df['distance'][i] = all_Washoutfish_df['distance'][i-1] + distancestep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['AbsYr'][i] = all_Washoutfish_df['AbsYr'][i-1] + AbsYrstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:39: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.00263977050781' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Washoutfish_df['AbsYr'][i] = all_Washoutfish_df['AbsYr'][i-1] + AbsYrstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['Yds'][i] = all_Washoutfish_df['Yds'][i-1] + Ydsstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-9.757903140574716e-06' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Washoutfish_df['Yds'][i] = all_Washoutfish_df['Yds'][i-1] + Ydsstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['FishV'][i] =  FishVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '14.470294100165205' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Washoutfish_df['FishV'][i] =  FishVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['FishVds'][i] =  FishVstepds\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.05348939531951345' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Washoutfish_df['FishVds'][i] =  FishVstepds\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['RobotV'][i] = all_Washoutfish_df['RobotV'][i-1] + RobotVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:43: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1.9215951886456641' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Washoutfish_df['RobotV'][i] = all_Washoutfish_df['RobotV'][i-1] + RobotVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Washoutfish_df['RobotVds'][i] = all_Washoutfish_df['RobotVds'][i-1] + RobotVstepds\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\206409895.py:44: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.007103170397094381' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Washoutfish_df['RobotVds'][i] = all_Washoutfish_df['RobotVds'][i-1] + RobotVstepds\n"
     ]
    }
   ],
   "source": [
    "# create  column, calculate the real distance of robot of each experiment\n",
    "all_Washoutfish_df['distance'] = 0  # initialize distance column with 0\n",
    "all_Washoutfish_df['distance'][0] = 0\n",
    "all_Washoutfish_df['AbsYr'] = 0  # initialize distance column with 0\n",
    "all_Washoutfish_df['AbsYr'][0] = 0\n",
    "all_Washoutfish_df['Yds'] = 0  # initialize distance column with 0\n",
    "all_Washoutfish_df['Yds'][0] = 0\n",
    "all_Washoutfish_df['FishV'] = 0  # initialize distance column with 0\n",
    "all_Washoutfish_df['FishV'][0] = 0\n",
    "all_Washoutfish_df['FishVds'] = 0  # initialize distance column with 0\n",
    "all_Washoutfish_df['FishVds'][0] = 0\n",
    "all_Washoutfish_df['RobotV'] = 0  # initialize distance column with 0\n",
    "all_Washoutfish_df['RobotV'][0] = 0\n",
    "all_Washoutfish_df['RobotVds'] = 0  # initialize distance column with 0\n",
    "all_Washoutfish_df['RobotVds'][0] = 0\n",
    "\n",
    "for i in range(1, len(all_Washoutfish_df)):\n",
    "    distancestep = math.sqrt((all_Washoutfish_df['Xr'][i] - all_Washoutfish_df['Xr'][i-1])**2 + (all_Washoutfish_df['Yr'][i] - all_Washoutfish_df['Yr'][i-1])**2)\n",
    "    AbsYrstep = np.abs(all_Washoutfish_df['Yr'][i])\n",
    "    Ydsstep = (all_Washoutfish_df['Yr'][i])*distancestep\n",
    "    FishVstep = all_Washoutfish_df['YAWf'][i]* 180 / np.pi + 180\n",
    "    FishVstepds = (all_Washoutfish_df['YAWf'][i]* 180 / np.pi + 180)*distancestep\n",
    "    RobotVstep = math.atan2(( all_Washoutfish_df['Yr'][i] - all_Washoutfish_df['Yr'][i-1]),(all_Washoutfish_df['Xr'][i] - all_Washoutfish_df['Xr'][i-1]))\n",
    "    RobotVstepds = RobotVstep*distancestep\n",
    "\n",
    "    if all_Washoutfish_df['time'][i] == 0:\n",
    "        all_Washoutfish_df['distance'][i] = 0\n",
    "        all_Washoutfish_df['AbsYr'][i]=0\n",
    "        all_Washoutfish_df['Yds'][i]=0\n",
    "        all_Washoutfish_df['FishV'][i] = 0\n",
    "        all_Washoutfish_df['FishVds'][i] = 0\n",
    "        all_Washoutfish_df['RobotV'][i] = 0\n",
    "        all_Washoutfish_df['RobotVds'][i] = 0       \n",
    "        \n",
    "\n",
    "        \n",
    "    else:\n",
    "        all_Washoutfish_df['distance'][i] = all_Washoutfish_df['distance'][i-1] + distancestep\n",
    "        all_Washoutfish_df['AbsYr'][i] = all_Washoutfish_df['AbsYr'][i-1] + AbsYrstep\n",
    "        all_Washoutfish_df['Yds'][i] = all_Washoutfish_df['Yds'][i-1] + Ydsstep\n",
    "        all_Washoutfish_df['FishV'][i] =  FishVstep\n",
    "        all_Washoutfish_df['FishVds'][i] =  FishVstepds\n",
    "        all_Washoutfish_df['RobotV'][i] = all_Washoutfish_df['RobotV'][i-1] + RobotVstep\n",
    "        all_Washoutfish_df['RobotVds'][i] = all_Washoutfish_df['RobotVds'][i-1] + RobotVstepds      \n",
    "\n",
    "\n",
    "# set last time value equal to second to last\n",
    "all_Washoutfish_df['time'].iloc[-1] = all_Washoutfish_df['time'].iloc[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Washoutfish_df = all_Washoutfish_df.sort_values(by=['fish_id', 'date', 'trial_id'])\n",
    "\n",
    "# Reset the index of the grouped DataFrame\n",
    "all_Washoutfish_df.reset_index(inplace=True)\n",
    "\n",
    "# Define the path to the CSV file to store the all_fish_df\n",
    "all_Washoutfish_td_path = os.path.join(Washout_new_df_dir, \"all_Washouttd_df.csv\")\n",
    "# Save the all_fish_df to the CSV file\n",
    "all_Washoutfish_df.to_csv(all_Washoutfish_td_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same thing for all Rotation fish "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\203756469.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['time'][0] = 0  # set first time value to 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\203756469.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['time'][i] = all_Rotationfish_df['time'][i-1] + diff\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\203756469.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.07068800930000307' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Rotationfish_df['time'][i] = all_Rotationfish_df['time'][i-1] + diff\n"
     ]
    }
   ],
   "source": [
    "# create time column, calculate the real time of each experiment\n",
    "all_Rotationfish_df['time'] = 0  # initialize time column with 0\n",
    "all_Rotationfish_df['time'][0] = 0  # set first time value to 0\n",
    "\n",
    "for i in range(1, len(all_Rotationfish_df)):\n",
    "    diff = all_Rotationfish_df['t'][i] - all_Rotationfish_df['t'][i-1]\n",
    "    if diff > 1.5 or diff < 0 :\n",
    "        if all_Rotationfish_df['experiment_id'][i]!=all_Rotationfish_df['experiment_id'][i-1]:\n",
    "            all_Rotationfish_df['time'][i] = 0 \n",
    "        else:\n",
    "            all_Rotationfish_df['time'][i] = all_Rotationfish_df['time'][i-1] + diff\n",
    "    else:\n",
    "        all_Rotationfish_df['time'][i] = all_Rotationfish_df['time'][i-1] + diff\n",
    "\n",
    "# set last time value equal to second to last\n",
    "all_Rotationfish_df['time'].iloc[-1] = all_Rotationfish_df['time'].iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['distance'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['AbsYr'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['Yds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['FishV'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['FishVds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['RobotV'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['RobotVds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['distance'][i] = all_Rotationfish_df['distance'][i-1] + distancestep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.0009752876185472326' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Rotationfish_df['distance'][i] = all_Rotationfish_df['distance'][i-1] + distancestep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['AbsYr'][i] = all_Rotationfish_df['AbsYr'][i-1] + AbsYrstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:37: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.00159454345703' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Rotationfish_df['AbsYr'][i] = all_Rotationfish_df['AbsYr'][i-1] + AbsYrstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['Yds'][i] = all_Rotationfish_df['Yds'][i-1] + Ydsstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:38: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-1.5551384908768602e-06' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Rotationfish_df['Yds'][i] = all_Rotationfish_df['Yds'][i-1] + Ydsstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['FishV'][i] =  FishVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:39: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '113.11420798304522' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Rotationfish_df['FishV'][i] =  FishVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['FishVds'][i] =  FishVstepds\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.11031888652764053' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Rotationfish_df['FishVds'][i] =  FishVstepds\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['RobotV'][i] = all_Rotationfish_df['RobotV'][i-1] + RobotVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:41: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.41465007951322497' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Rotationfish_df['RobotV'][i] = all_Rotationfish_df['RobotV'][i-1] + RobotVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Rotationfish_df['RobotVds'][i] = all_Rotationfish_df['RobotVds'][i-1] + RobotVstepds\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\769414200.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.0004044030885788738' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Rotationfish_df['RobotVds'][i] = all_Rotationfish_df['RobotVds'][i-1] + RobotVstepds\n"
     ]
    }
   ],
   "source": [
    "# create  column, calculate the real distance of robot of each experiment\n",
    "all_Rotationfish_df['distance'] = 0  # initialize distance column with 0\n",
    "all_Rotationfish_df['distance'][0] = 0\n",
    "all_Rotationfish_df['AbsYr'] = 0  # initialize distance column with 0\n",
    "all_Rotationfish_df['AbsYr'][0] = 0\n",
    "all_Rotationfish_df['Yds'] = 0  # initialize distance column with 0\n",
    "all_Rotationfish_df['Yds'][0] = 0\n",
    "all_Rotationfish_df['FishV'] = 0  # initialize distance column with 0\n",
    "all_Rotationfish_df['FishV'][0] = 0\n",
    "all_Rotationfish_df['FishVds'] = 0  # initialize distance column with 0\n",
    "all_Rotationfish_df['FishVds'][0] = 0\n",
    "all_Rotationfish_df['RobotV'] = 0  # initialize distance column with 0\n",
    "all_Rotationfish_df['RobotV'][0] = 0\n",
    "all_Rotationfish_df['RobotVds'] = 0  # initialize distance column with 0\n",
    "all_Rotationfish_df['RobotVds'][0] = 0\n",
    "\n",
    "for i in range(1, len(all_Rotationfish_df)):\n",
    "    distancestep = math.sqrt((all_Rotationfish_df['Xr'][i] - all_Rotationfish_df['Xr'][i-1])**2 + (all_Rotationfish_df['Yr'][i] - all_Rotationfish_df['Yr'][i-1])**2)\n",
    "    AbsYrstep = np.abs(all_Rotationfish_df['Yr'][i])\n",
    "    Ydsstep = (all_Rotationfish_df['Yr'][i])*distancestep\n",
    "    FishVstep = all_Rotationfish_df['YAWf'][i]* 180 / np.pi + 180\n",
    "    FishVstepds = (all_Rotationfish_df['YAWf'][i]* 180 / np.pi + 180)*distancestep\n",
    "    RobotVstep = math.atan2(( all_Rotationfish_df['Yr'][i] - all_Rotationfish_df['Yr'][i-1]),(all_Rotationfish_df['Xr'][i] - all_Rotationfish_df['Xr'][i-1]))\n",
    "    RobotVstepds = RobotVstep*distancestep\n",
    "\n",
    "    if all_Rotationfish_df['time'][i] == 0:\n",
    "        all_Rotationfish_df['distance'][i] = 0\n",
    "        all_Rotationfish_df['AbsYr'][i]=0\n",
    "        all_Rotationfish_df['Yds'][i]=0\n",
    "        all_Rotationfish_df['FishV'][i] = 0\n",
    "        all_Rotationfish_df['FishVds'][i] = 0\n",
    "        all_Rotationfish_df['RobotV'][i] = 0\n",
    "        all_Rotationfish_df['RobotVds'][i] = 0 \n",
    "        \n",
    "    else:\n",
    "        all_Rotationfish_df['distance'][i] = all_Rotationfish_df['distance'][i-1] + distancestep\n",
    "        all_Rotationfish_df['AbsYr'][i] = all_Rotationfish_df['AbsYr'][i-1] + AbsYrstep\n",
    "        all_Rotationfish_df['Yds'][i] = all_Rotationfish_df['Yds'][i-1] + Ydsstep\n",
    "        all_Rotationfish_df['FishV'][i] =  FishVstep\n",
    "        all_Rotationfish_df['FishVds'][i] =  FishVstepds\n",
    "        all_Rotationfish_df['RobotV'][i] = all_Rotationfish_df['RobotV'][i-1] + RobotVstep\n",
    "        all_Rotationfish_df['RobotVds'][i] = all_Rotationfish_df['RobotVds'][i-1] + RobotVstepds   \n",
    "\n",
    "# set last time value equal to second to last\n",
    "all_Rotationfish_df['time'].iloc[-1] = all_Rotationfish_df['time'].iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Rotationfish_df = all_Rotationfish_df.sort_values(by=['fish_id', 'date', 'trial_id'])\n",
    "\n",
    "# Reset the index of the grouped DataFrame\n",
    "all_Rotationfish_df.reset_index(inplace=True)\n",
    "\n",
    "# Define the path to the CSV file to store the all_fish_df\n",
    "all_Rotationfish_td_path = os.path.join(Rotation_new_df_dir, \"all_Rotationtd_df.csv\")\n",
    "# Save the all_fish_df to the CSV file\n",
    "all_Rotationfish_df.to_csv(all_Rotationfish_td_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\3634653313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['time'][0] = 0  # set first time value to 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\3634653313.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['time'][i] = all_ReRotationfish_df['time'][i-1] + diff\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\3634653313.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.07041883469999988' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReRotationfish_df['time'][i] = all_ReRotationfish_df['time'][i-1] + diff\n"
     ]
    }
   ],
   "source": [
    "# create time column, calculate the real time of each experiment\n",
    "all_ReRotationfish_df['time'] = 0  # initialize time column with 0\n",
    "all_ReRotationfish_df['time'][0] = 0  # set first time value to 0\n",
    "\n",
    "for i in range(1, len(all_ReRotationfish_df)):\n",
    "    diff = all_ReRotationfish_df['t'][i] - all_ReRotationfish_df['t'][i-1]\n",
    "    if diff > 1.5 or diff < 0:\n",
    "        if all_ReRotationfish_df['experiment_id'][i] != all_ReRotationfish_df['experiment_id'][i-1]:\n",
    "            all_ReRotationfish_df['time'][i] = 0\n",
    "        else:\n",
    "            all_ReRotationfish_df['time'][i] = all_ReRotationfish_df['time'][i-1] + diff\n",
    "    else:\n",
    "        all_ReRotationfish_df['time'][i] = all_ReRotationfish_df['time'][i-1] + diff\n",
    "\n",
    "# set last time value equal to second to last\n",
    "all_ReRotationfish_df['time'].iloc[-1] = all_ReRotationfish_df['time'].iloc[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['distance'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['AbsYr'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['Yds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['FishV'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['FishVds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['RobotV'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['RobotVds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['distance'][i] = all_ReRotationfish_df['distance'][i-1] + distancestep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.002056249214712379' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReRotationfish_df['distance'][i] = all_ReRotationfish_df['distance'][i-1] + distancestep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['AbsYr'][i] = all_ReRotationfish_df['AbsYr'][i-1] + AbsYrstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.000480651855469' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReRotationfish_df['AbsYr'][i] = all_ReRotationfish_df['AbsYr'][i-1] + AbsYrstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['Yds'][i] = all_ReRotationfish_df['Yds'][i-1] + Ydsstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '9.88340000358179e-07' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReRotationfish_df['Yds'][i] = all_ReRotationfish_df['Yds'][i-1] + Ydsstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['FishV'][i] = FishVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:37: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '4.573921259760823' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReRotationfish_df['FishV'][i] = FishVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['FishVds'][i] =  FishVstepds\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:38: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.009405121998539448' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReRotationfish_df['FishVds'][i] =  FishVstepds\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['RobotV'][i] = all_ReRotationfish_df['RobotV'][i-1] + RobotVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:39: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '3.0211303729438805' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReRotationfish_df['RobotV'][i] = all_ReRotationfish_df['RobotV'][i-1] + RobotVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_ReRotationfish_df['RobotVds'][i] = all_ReRotationfish_df['RobotVds'][i-1] + RobotVstepds\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\455958260.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.04296426032525657' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_ReRotationfish_df['RobotVds'][i] = all_ReRotationfish_df['RobotVds'][i-1] + RobotVstepds\n"
     ]
    }
   ],
   "source": [
    "# create column, calculate the real distance of robot of each experiment\n",
    "all_ReRotationfish_df['distance'] = 0  # initialize distance column with 0\n",
    "all_ReRotationfish_df['distance'][0] = 0\n",
    "all_ReRotationfish_df['AbsYr'] = 0  # initialize distance column with 0\n",
    "all_ReRotationfish_df['AbsYr'][0] = 0\n",
    "all_ReRotationfish_df['Yds'] = 0  # initialize distance column with 0\n",
    "all_ReRotationfish_df['Yds'][0] = 0\n",
    "all_ReRotationfish_df['FishV'] = 0  # initialize distance column with 0\n",
    "all_ReRotationfish_df['FishV'][0] = 0\n",
    "all_ReRotationfish_df['FishVds'] = 0  # initialize distance column with 0\n",
    "all_ReRotationfish_df['FishVds'][0] = 0\n",
    "all_ReRotationfish_df['RobotV'] = 0  # initialize distance column with 0\n",
    "all_ReRotationfish_df['RobotV'][0] = 0\n",
    "all_ReRotationfish_df['RobotVds'] = 0  # initialize distance column with 0\n",
    "all_ReRotationfish_df['RobotVds'][0] = 0\n",
    "\n",
    "for i in range(1, len(all_ReRotationfish_df)):\n",
    "    distancestep = math.sqrt((all_ReRotationfish_df['Xr'][i] - all_ReRotationfish_df['Xr'][i-1])**2 + (all_ReRotationfish_df['Yr'][i] - all_ReRotationfish_df['Yr'][i-1])**2)\n",
    "    AbsYrstep = np.abs(all_ReRotationfish_df['Yr'][i])\n",
    "    Ydsstep = np.abs(all_ReRotationfish_df['Yr'][i]) * distancestep\n",
    "    FishVstep = all_ReRotationfish_df['YAWf'][i] * 180 / np.pi + 180\n",
    "    FishVstepds = (all_ReRotationfish_df['YAWf'][i] * 180 / np.pi + 180) * distancestep\n",
    "\n",
    "    if all_ReRotationfish_df['time'][i] == 0:\n",
    "        all_ReRotationfish_df['distance'][i] = 0\n",
    "        all_ReRotationfish_df['AbsYr'][i] = 0\n",
    "        all_ReRotationfish_df['Yds'][i] = 0\n",
    "        all_ReRotationfish_df['FishV'][i] = 0\n",
    "        all_ReRotationfish_df['FishVds'][i] = 0\n",
    "        all_ReRotationfish_df['RobotV'][i] = 0\n",
    "        all_ReRotationfish_df['RobotVds'][i] = 0 \n",
    "\n",
    "    else:\n",
    "        all_ReRotationfish_df['distance'][i] = all_ReRotationfish_df['distance'][i-1] + distancestep\n",
    "        all_ReRotationfish_df['AbsYr'][i] = all_ReRotationfish_df['AbsYr'][i-1] + AbsYrstep\n",
    "        all_ReRotationfish_df['Yds'][i] = all_ReRotationfish_df['Yds'][i-1] + Ydsstep\n",
    "        all_ReRotationfish_df['FishV'][i] = FishVstep\n",
    "        all_ReRotationfish_df['FishVds'][i] =  FishVstepds\n",
    "        all_ReRotationfish_df['RobotV'][i] = all_ReRotationfish_df['RobotV'][i-1] + RobotVstep\n",
    "        all_ReRotationfish_df['RobotVds'][i] = all_ReRotationfish_df['RobotVds'][i-1] + RobotVstepds   \n",
    "\n",
    "# set last time value equal to the second to last\n",
    "all_ReRotationfish_df['time'].iloc[-1] = all_ReRotationfish_df['time'].iloc[-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ReRotationfish_df = all_ReRotationfish_df.sort_values(by=['fish_id', 'date', 'trial_id'])\n",
    "\n",
    "# Reset the index of the grouped DataFrame\n",
    "all_ReRotationfish_df.reset_index(inplace=True)\n",
    "\n",
    "# Define the path to the CSV file to store the all_fish_df\n",
    "all_ReRotationfish_td_path = os.path.join(ReRotation_new_df_dir, \"all_ReRotationtd_df.csv\")\n",
    "# Save the all_fish_df to the CSV file\n",
    "all_ReRotationfish_df.to_csv(all_ReRotationfish_td_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same thing for all Baseline fish "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2927617355.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Baselinefish_df['time'][0] = 0  # set first time value to 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2927617355.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Baselinefish_df['time'][i] = all_Baselinefish_df['time'][i-1] + diff\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2927617355.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.0656099318999992' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Baselinefish_df['time'][i] = all_Baselinefish_df['time'][i-1] + diff\n"
     ]
    }
   ],
   "source": [
    "# create time column, calculate the real time of each experiment\n",
    "all_Baselinefish_df['time'] = 0  # initialize time column with 0\n",
    "all_Baselinefish_df['time'][0] = 0  # set first time value to 0\n",
    "\n",
    "for i in range(1, len(all_Baselinefish_df)):\n",
    "    diff = all_Baselinefish_df['t'][i] - all_Baselinefish_df['t'][i-1]\n",
    "    if diff > 1.5 or diff < 0 :\n",
    "        if all_Baselinefish_df['experiment_id'][i]!=all_Baselinefish_df['experiment_id'][i-1]:\n",
    "            all_Baselinefish_df['time'][i] = 0 \n",
    "        else:\n",
    "            all_Baselinefish_df['time'][i] = all_Baselinefish_df['time'][i-1] + diff\n",
    "    else:\n",
    "        all_Baselinefish_df['time'][i] = all_Baselinefish_df['time'][i-1] + diff\n",
    "\n",
    "# set last time value equal to second to last\n",
    "all_Baselinefish_df['time'].iloc[-1] = all_Baselinefish_df['time'].iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Baselinefish_df['distance'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Baselinefish_df['AbsYr'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Baselinefish_df['Yds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Baselinefish_df['FishV'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Baselinefish_df['FishVds'][0] = 0\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Baselinefish_df['distance'][i] = all_Baselinefish_df['distance'][i-1] + distancestep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.001153540737192356' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Baselinefish_df['distance'][i] = all_Baselinefish_df['distance'][i-1] + distancestep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Baselinefish_df['AbsYr'][i] = all_Baselinefish_df['AbsYr'][i-1] + AbsYrstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.0136795043945' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Baselinefish_df['AbsYr'][i] = all_Baselinefish_df['AbsYr'][i-1] + AbsYrstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Baselinefish_df['Yds'][i] = all_Baselinefish_df['Yds'][i-1] + Ydsstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1.5779865583657606e-05' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Baselinefish_df['Yds'][i] = all_Baselinefish_df['Yds'][i-1] + Ydsstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Baselinefish_df['FishV'][i] =  FishVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:31: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '342.89727103074057' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Baselinefish_df['FishV'][i] =  FishVstep\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_Baselinefish_df['FishVds'][i] =  FishVstepds\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2594901333.py:32: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.3955459708060476' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  all_Baselinefish_df['FishVds'][i] =  FishVstepds\n"
     ]
    }
   ],
   "source": [
    "# create  column, calculate the real distance of robot of each experiment\n",
    "all_Baselinefish_df['distance'] = 0  # initialize distance column with 0\n",
    "all_Baselinefish_df['distance'][0] = 0\n",
    "all_Baselinefish_df['AbsYr'] = 0  # initialize distance column with 0\n",
    "all_Baselinefish_df['AbsYr'][0] = 0\n",
    "all_Baselinefish_df['Yds'] = 0  # initialize distance column with 0\n",
    "all_Baselinefish_df['Yds'][0] = 0\n",
    "all_Baselinefish_df['FishV'] = 0  # initialize distance column with 0\n",
    "all_Baselinefish_df['FishV'][0] = 0\n",
    "all_Baselinefish_df['FishVds'] = 0  # initialize distance column with 0\n",
    "all_Baselinefish_df['FishVds'][0] = 0\n",
    "\n",
    "for i in range(1, len(all_Baselinefish_df)):\n",
    "    distancestep = math.sqrt((all_Baselinefish_df['Xr'][i] - all_Baselinefish_df['Xr'][i-1])**2 + (all_Baselinefish_df['Yr'][i] - all_Baselinefish_df['Yr'][i-1])**2)\n",
    "    AbsYrstep = np.abs(all_Baselinefish_df['Yr'][i])\n",
    "    Ydsstep = (all_Baselinefish_df['Yr'][i])*distancestep\n",
    "    FishVstep = all_Baselinefish_df['YAWf'][i]* 180 / np.pi + 180\n",
    "    FishVstepds = (all_Baselinefish_df['YAWf'][i]* 180 / np.pi + 180)*distancestep\n",
    "\n",
    "    if all_Baselinefish_df['time'][i] == 0:\n",
    "        all_Baselinefish_df['distance'][i] = 0\n",
    "        all_Baselinefish_df['AbsYr'][i]=0\n",
    "        all_Baselinefish_df['Yds'][i]=0\n",
    "        all_Baselinefish_df['FishV'][i] = 0\n",
    "        all_Baselinefish_df['FishVds'][i] = 0\n",
    "        \n",
    "    else:\n",
    "        all_Baselinefish_df['distance'][i] = all_Baselinefish_df['distance'][i-1] + distancestep\n",
    "        all_Baselinefish_df['AbsYr'][i] = all_Baselinefish_df['AbsYr'][i-1] + AbsYrstep\n",
    "        all_Baselinefish_df['Yds'][i] = all_Baselinefish_df['Yds'][i-1] + Ydsstep\n",
    "        all_Baselinefish_df['FishV'][i] =  FishVstep\n",
    "        all_Baselinefish_df['FishVds'][i] =  FishVstepds\n",
    "\n",
    "# set last time value equal to second to last\n",
    "all_Baselinefish_df['time'].iloc[-1] = all_Baselinefish_df['time'].iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Baselinefish_df = all_Baselinefish_df.sort_values(by=['fish_id', 'date', 'trial_id'])\n",
    "\n",
    "# Reset the index of the grouped DataFrame\n",
    "all_Baselinefish_df.reset_index(inplace=True)\n",
    "\n",
    "# Define the path to the CSV file to store the all_fish_df\n",
    "all_Baselinefish_td_path = os.path.join(Baseline_new_df_dir, \"all_Baselinetd_df.csv\")\n",
    "# Save the all_fish_df to the CSV file\n",
    "all_Baselinefish_df.to_csv(all_Baselinefish_td_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "all_Baselinefish_df['date'] = pd.to_datetime(all_Baselinefish_df['date'])\n",
    "\n",
    "# Create a boolean mask to identify the rows where df['time'] = 0 for the next row\n",
    "Bmask = (all_Baselinefish_df['time'].shift(-1) == 0)\n",
    "\n",
    "# Filter the DataFrame to keep only the last rows of each trial\n",
    "filtered_all_Baselinefish_df = all_Baselinefish_df[Bmask]\n",
    "\n",
    "# Initialize lists to store the calculated 'distance' and absolute maximum 'Yr' values\n",
    "distance_values = []\n",
    "abs_max_yr_values = []\n",
    "trial_id_values = []\n",
    "# FishAngle_values = []\n",
    "\n",
    "# Loop through the filtered DataFrame and compute the 'distance' and absolute maximum 'Yr' values\n",
    "for index, row in filtered_all_Baselinefish_df.iterrows():\n",
    "    experiment_id = row['experiment_id']\n",
    "    trial_df = filtered_all_Baselinefish_df[filtered_all_Baselinefish_df['experiment_id'] == experiment_id]\n",
    "    distance_values.append(trial_df.iloc[-1]['distance'])\n",
    "    trial_id_values.append(trial_df['trial_id'])\n",
    "    abs_max_yr_values.append(trial_df['Yr'].abs().max())\n",
    "    # FishAngle_values.append(trial_df[''])\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "Baseline_trial_new_df = pd.DataFrame({\n",
    "    'fish_id': filtered_all_Baselinefish_df['fish_id'],\n",
    "    'date': filtered_all_Baselinefish_df['date'],\n",
    "    'time': filtered_all_Baselinefish_df['time'],\n",
    "    'Xr': filtered_all_Baselinefish_df['Xr'],\n",
    "    'Yr': filtered_all_Baselinefish_df['Yr'],\n",
    "    'experiment_id': filtered_all_Baselinefish_df['experiment_id'],\n",
    "    'trialinterval': filtered_all_Baselinefish_df['trial_id'],\n",
    "    'distance': distance_values,\n",
    "    'AbsMax_Yr': abs_max_yr_values,\n",
    "    'AbsYr_sum': filtered_all_Baselinefish_df['AbsYr'],\n",
    "    'Yds_sum': filtered_all_Baselinefish_df['Yds'],\n",
    "    'FishV_sum': filtered_all_Baselinefish_df['FishV'],\n",
    "    'FishVds_sum': filtered_all_Baselinefish_df['FishVds'],\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by 'fish_id' and 'date'\n",
    "Baseline_trial_new_df.sort_values(by=['fish_id', 'date'], inplace=True)\n",
    "\n",
    "# Calculate the 'Day' column based on the date difference\n",
    "Baseline_trial_new_df['Day'] = (Baseline_trial_new_df['date'] - Baseline_trial_new_df.groupby('fish_id')['date'].transform('first')).dt.days + 1\n",
    "\n",
    "# Add a new column 'Day' to represent the date as a number from 1 to the end for each fish\n",
    "Baseline_trial_new_df['Trialday'] = Baseline_trial_new_df.groupby('fish_id')['date'].rank(method='dense').astype(int)\n",
    "\n",
    "def calculate_success(row):\n",
    "    if row['Xr'] < rect_pos[0] + rect_width and criterion_Yr * (-1) < row['Yr'] < criterion_Yr:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calculate_excellent(row):\n",
    "    if row['success'] == 1 and row['distance'] < criterion_dis:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to create the 'success' column\n",
    "Baseline_trial_new_df['success'] = Baseline_trial_new_df.apply(calculate_success, axis=1)\n",
    "Baseline_trial_new_df['excellent'] = Baseline_trial_new_df.apply(calculate_excellent, axis=1)\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "Baseline_trial_path = r'D:\\FOV2\\BRWanalysis\\data\\Baseline\\all_Baselineeachtrial.csv'\n",
    "Baseline_trial_new_df = Baseline_trial_new_df.reset_index(drop=True)\n",
    "\n",
    "Baseline_trial_new_df.to_csv(Baseline_trial_path, index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert rawdata into data of interest for each trial,  distinguish by different session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "all_Washoutfish_df['date'] = pd.to_datetime(all_Washoutfish_df['date'])\n",
    "\n",
    "# Create a boolean mask to identify the rows where df['time'] = 0 for the next row\n",
    "mask = (all_Washoutfish_df['time'].shift(-1) == 0)\n",
    "\n",
    "\n",
    "\n",
    "# Filter the DataFrame to keep only the last rows of each trial\n",
    "filtered_all_Washoutfish_df = all_Washoutfish_df[mask]\n",
    "\n",
    "# Initialize lists to store the calculated 'distance' and absolute maximum 'Yr' values\n",
    "distance_values = []\n",
    "abs_max_yr_values = []\n",
    "trial_id_values= []\n",
    "#FishAngle_values= []\n",
    "\n",
    "\n",
    "# Loop through the filtered DataFrame and compute the 'distance' and absolute maximum 'Yr' values\n",
    "for index, row in filtered_all_Washoutfish_df.iterrows():\n",
    "    experiment_id = row['experiment_id']\n",
    "    trial_df = filtered_all_Washoutfish_df [filtered_all_Washoutfish_df ['experiment_id'] == experiment_id]\n",
    "    distance_values.append(trial_df.iloc[-1]['distance'])\n",
    "    trial_id_values.append(trial_df['trial_id'])\n",
    "    abs_max_yr_values.append(trial_df['Yr'].abs().max())\n",
    "  #  FishAngle_values.append(trial_df[''])\n",
    "# Create a new DataFrame with the required columns\n",
    "Washout_trial_new_df = pd.DataFrame({\n",
    "    'fish_id': filtered_all_Washoutfish_df['fish_id'],\n",
    "    'date': filtered_all_Washoutfish_df['date'],\n",
    "    'time': filtered_all_Washoutfish_df['time'],\n",
    "    'Xr':filtered_all_Washoutfish_df['Xr'],\n",
    "    'Yr':filtered_all_Washoutfish_df['Yr'],\n",
    "    'experiment_id': filtered_all_Washoutfish_df['experiment_id'],\n",
    "    'trialinterval':filtered_all_Washoutfish_df['trial_id'],\n",
    "    'distance': distance_values,\n",
    "    'AbsMax_Yr': abs_max_yr_values,\n",
    "    'AbsYr_sum':filtered_all_Washoutfish_df['AbsYr'],\n",
    "    'Yds_sum':filtered_all_Washoutfish_df['Yds'],\n",
    "    'FishV_sum':filtered_all_Washoutfish_df['FishV'],\n",
    "    'FishVds_sum':filtered_all_Washoutfish_df['FishVds'],\n",
    "    'RobotV_sum':filtered_all_Washoutfish_df['RobotV'],\n",
    "    'RobotVds_sum':filtered_all_Washoutfish_df['RobotVds'],\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by 'fish_id' and 'date'\n",
    "Washout_trial_new_df.sort_values(by=['fish_id', 'date'], inplace=True)\n",
    "\n",
    "# Calculate the 'Day' column based on the date difference\n",
    "Washout_trial_new_df['Day'] = (Washout_trial_new_df['date'] - Washout_trial_new_df.groupby('fish_id')['date'].transform('first')).dt.days + 1\n",
    "\n",
    "# Add a new column 'Day' to represent the date as a number from 1 to the end for each fish\n",
    "Washout_trial_new_df['Trialday'] = Washout_trial_new_df.groupby('fish_id')['date'].rank(method='dense').astype(int)\n",
    "\n",
    "\n",
    "def calculate_success(row):\n",
    "    if row['Xr'] < rect_pos[0]+rect_width and criterion_Yr*(-1)< row['Yr'] < criterion_Yr:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def calculate_excellent(row):\n",
    "    if row['success'] == 1 and row['distance'] < criterion_dis:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "# Apply the function to create the 'success' column\n",
    "Washout_trial_new_df['success'] = Washout_trial_new_df.apply(calculate_success, axis=1)\n",
    "Washout_trial_new_df['excellent'] = Washout_trial_new_df.apply(calculate_excellent, axis=1)\n",
    "\n",
    "\n",
    "Washout_trial_path = r'D:\\FOV2\\BRWanalysis\\data\\Washout\\all_Washouteachtrial.csv'\n",
    "Washout_trial_new_df = Washout_trial_new_df.reset_index(drop=True)\n",
    "Washout_trial_new_df.to_csv(Washout_trial_path, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "all_Rotationfish_df['date'] = pd.to_datetime(all_Rotationfish_df['date'])\n",
    "\n",
    "# Create a boolean mask to identify the rows where df['time'] = 0 for the next row\n",
    "Rmask = (all_Rotationfish_df['time'].shift(-1) == 0)\n",
    "\n",
    "# Filter the DataFrame to keep only the last rows of each trial\n",
    "filtered_all_Rotationfish_df = all_Rotationfish_df[Rmask]\n",
    "\n",
    "# Initialize lists to store the calculated 'distance' and absolute maximum 'Yr' values\n",
    "distance_values = []\n",
    "abs_max_yr_values = []\n",
    "trial_id_values = []\n",
    "# FishAngle_values = []\n",
    "\n",
    "# Loop through the filtered DataFrame and compute the 'distance' and absolute maximum 'Yr' values\n",
    "for index, row in filtered_all_Rotationfish_df.iterrows():\n",
    "    experiment_id = row['experiment_id']\n",
    "    trial_df = filtered_all_Rotationfish_df[filtered_all_Rotationfish_df['experiment_id'] == experiment_id]\n",
    "    distance_values.append(trial_df.iloc[-1]['distance'])\n",
    "    trial_id_values.append(trial_df['trial_id'])\n",
    "    abs_max_yr_values.append(trial_df['Yr'].abs().max())\n",
    "    # FishAngle_values.append(trial_df[''])\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "Rotation_trial_new_df = pd.DataFrame({\n",
    "    'fish_id': filtered_all_Rotationfish_df['fish_id'],\n",
    "    'date': filtered_all_Rotationfish_df['date'],\n",
    "    'time': filtered_all_Rotationfish_df['time'],\n",
    "    'Xr': filtered_all_Rotationfish_df['Xr'],\n",
    "    'Yr': filtered_all_Rotationfish_df['Yr'],\n",
    "    'experiment_id': filtered_all_Rotationfish_df['experiment_id'],\n",
    "    'trialinterval': filtered_all_Rotationfish_df['trial_id'],\n",
    "    'distance': distance_values,\n",
    "    'AbsMax_Yr': abs_max_yr_values,\n",
    "    'AbsYr_sum': filtered_all_Rotationfish_df['AbsYr'],\n",
    "    'Yds_sum': filtered_all_Rotationfish_df['Yds'],\n",
    "    'FishV_sum': filtered_all_Rotationfish_df['FishV'],\n",
    "    'FishVds_sum': filtered_all_Rotationfish_df['FishVds'],\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by 'fish_id' and 'date'\n",
    "Rotation_trial_new_df.sort_values(by=['fish_id', 'date'], inplace=True)\n",
    "\n",
    "# Calculate the 'Day' column based on the date difference\n",
    "Rotation_trial_new_df['Day'] = (Rotation_trial_new_df['date'] - Rotation_trial_new_df.groupby('fish_id')['date'].transform('first')).dt.days + 1\n",
    "\n",
    "# Add a new column 'Day' to represent the date as a number from 1 to the end for each fish\n",
    "Rotation_trial_new_df['Trialday'] = Rotation_trial_new_df.groupby('fish_id')['date'].rank(method='dense').astype(int)\n",
    "\n",
    "def calculate_success(row):\n",
    "    if row['Xr'] < rect_pos[0] + rect_width and criterion_Yr * (-1) < row['Yr'] < criterion_Yr:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calculate_excellent(row):\n",
    "    if row['success'] == 1 and row['distance'] < criterion_dis:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to create the 'success' column\n",
    "Rotation_trial_new_df['success'] = Rotation_trial_new_df.apply(calculate_success, axis=1)\n",
    "Rotation_trial_new_df['excellent'] = Rotation_trial_new_df.apply(calculate_excellent, axis=1)\n",
    "# Save the new DataFrame to a CSV file\n",
    "Rotation_trial_path = r'D:\\FOV2\\BRWanalysis\\data\\Rotation\\all_Rotationeachtrial.csv'\n",
    "Rotation_trial_new_df = Rotation_trial_new_df.reset_index(drop=True)\n",
    "\n",
    "Rotation_trial_new_df.to_csv(Rotation_trial_path, index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "all_Rotationfish_df['date'] = pd.to_datetime(all_Rotationfish_df['date'])\n",
    "\n",
    "# Create a boolean mask to identify the rows where df['time'] = 0 for the next row\n",
    "Rmask = (all_Rotationfish_df['time'].shift(-1) == 0)\n",
    "\n",
    "# Filter the DataFrame to keep only the last rows of each trial\n",
    "filtered_all_Rotationfish_df = all_Rotationfish_df[Rmask]\n",
    "\n",
    "# Initialize lists to store the calculated 'distance' and absolute maximum 'Yr' values\n",
    "distance_values = []\n",
    "abs_max_yr_values = []\n",
    "trial_id_values = []\n",
    "# FishAngle_values = []\n",
    "\n",
    "# Loop through the filtered DataFrame and compute the 'distance' and absolute maximum 'Yr' values\n",
    "for index, row in filtered_all_Rotationfish_df.iterrows():\n",
    "    experiment_id = row['experiment_id']\n",
    "    trial_df = filtered_all_Rotationfish_df[filtered_all_Rotationfish_df['experiment_id'] == experiment_id]\n",
    "    distance_values.append(trial_df.iloc[-1]['distance'])\n",
    "    trial_id_values.append(trial_df['trial_id'])\n",
    "    abs_max_yr_values.append(trial_df['Yr'].abs().max())\n",
    "    # FishAngle_values.append(trial_df[''])\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "Rotation_trial_new_df = pd.DataFrame({\n",
    "    'fish_id': filtered_all_Rotationfish_df['fish_id'],\n",
    "    'date': filtered_all_Rotationfish_df['date'],\n",
    "    'time': filtered_all_Rotationfish_df['time'],\n",
    "    'Xr': filtered_all_Rotationfish_df['Xr'],\n",
    "    'Yr': filtered_all_Rotationfish_df['Yr'],\n",
    "    'experiment_id': filtered_all_Rotationfish_df['experiment_id'],\n",
    "    'trialinterval': filtered_all_Rotationfish_df['trial_id'],\n",
    "    'distance': distance_values,\n",
    "    'AbsMax_Yr': abs_max_yr_values,\n",
    "    'AbsYr_sum': filtered_all_Rotationfish_df['AbsYr'],\n",
    "    'Yds_sum': filtered_all_Rotationfish_df['Yds'],\n",
    "    'FishV_sum': filtered_all_Rotationfish_df['FishV'],\n",
    "    'FishVds_sum': filtered_all_Rotationfish_df['FishVds'],\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by 'fish_id' and 'date'\n",
    "Rotation_trial_new_df.sort_values(by=['fish_id', 'date'], inplace=True)\n",
    "\n",
    "# Calculate the 'Day' column based on the date difference\n",
    "Rotation_trial_new_df['Day'] = (Rotation_trial_new_df['date'] - Rotation_trial_new_df.groupby('fish_id')['date'].transform('first')).dt.days + 1\n",
    "\n",
    "# Add a new column 'Day' to represent the date as a number from 1 to the end for each fish\n",
    "Rotation_trial_new_df['Trialday'] = Rotation_trial_new_df.groupby('fish_id')['date'].rank(method='dense').astype(int)\n",
    "\n",
    "def calculate_success(row):\n",
    "    if row['Xr'] < rect_pos[0] + rect_width and criterion_Yr * (-1) < row['Yr'] < criterion_Yr:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calculate_excellent(row):\n",
    "    if row['success'] == 1 and row['distance'] < criterion_dis:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to create the 'success' column\n",
    "Rotation_trial_new_df['success'] = Rotation_trial_new_df.apply(calculate_success, axis=1)\n",
    "Rotation_trial_new_df['excellent'] = Rotation_trial_new_df.apply(calculate_excellent, axis=1)\n",
    "# Save the new DataFrame to a CSV file\n",
    "Rotation_trial_path = r'D:\\FOV2\\BRWanalysis\\data\\Rotation\\all_Rotationeachtrial.csv'\n",
    "Rotation_trial_new_df = Rotation_trial_new_df.reset_index(drop=True)\n",
    "\n",
    "Rotation_trial_new_df.to_csv(Rotation_trial_path, index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "all_ReRotationfish_df['date'] = pd.to_datetime(all_ReRotationfish_df['date'])\n",
    "\n",
    "# Create a boolean mask to identify the rows where df['time'] = 0 for the next row\n",
    "Rmask = (all_ReRotationfish_df['time'].shift(-1) == 0)\n",
    "\n",
    "# Filter the DataFrame to keep only the last rows of each trial\n",
    "filtered_all_ReRotationfish_df = all_ReRotationfish_df[Rmask]\n",
    "\n",
    "# Initialize lists to store the calculated 'distance' and absolute maximum 'Yr' values\n",
    "distance_values = []\n",
    "abs_max_yr_values = []\n",
    "trial_id_values = []\n",
    "\n",
    "# Loop through the filtered DataFrame and compute the 'distance' and absolute maximum 'Yr' values\n",
    "for index, row in filtered_all_ReRotationfish_df.iterrows():\n",
    "    experiment_id = row['experiment_id']\n",
    "    trial_df = filtered_all_ReRotationfish_df[filtered_all_ReRotationfish_df['experiment_id'] == experiment_id]\n",
    "    distance_values.append(trial_df.iloc[-1]['distance'])\n",
    "    trial_id_values.append(trial_df['trial_id'])\n",
    "    abs_max_yr_values.append(trial_df['Yr'].abs().max())\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "ReRotation_trial_new_df = pd.DataFrame({\n",
    "    'fish_id': filtered_all_ReRotationfish_df['fish_id'],\n",
    "    'date': filtered_all_ReRotationfish_df['date'],\n",
    "    'time': filtered_all_ReRotationfish_df['time'],\n",
    "    'Xr': filtered_all_ReRotationfish_df['Xr'],\n",
    "    'Yr': filtered_all_ReRotationfish_df['Yr'],\n",
    "    'experiment_id': filtered_all_ReRotationfish_df['experiment_id'],\n",
    "    'trialinterval': filtered_all_ReRotationfish_df['trial_id'],\n",
    "    'distance': distance_values,\n",
    "    'AbsMax_Yr': abs_max_yr_values,\n",
    "    'AbsYr_sum': filtered_all_ReRotationfish_df['AbsYr'],\n",
    "    'Yds_sum': filtered_all_ReRotationfish_df['Yds'],\n",
    "    'FishV_sum': filtered_all_ReRotationfish_df['FishV'],\n",
    "    'FishVds_sum': filtered_all_ReRotationfish_df['FishVds'],\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by 'fish_id' and 'date'\n",
    "ReRotation_trial_new_df.sort_values(by=['fish_id', 'date'], inplace=True)\n",
    "\n",
    "# Calculate the 'Day' column based on the date difference\n",
    "ReRotation_trial_new_df['Day'] = (ReRotation_trial_new_df['date'] - ReRotation_trial_new_df.groupby('fish_id')['date'].transform('first')).dt.days + 1\n",
    "\n",
    "# Add a new column 'Day' to represent the date as a number from 1 to the end for each fish\n",
    "ReRotation_trial_new_df['Trialday'] = ReRotation_trial_new_df.groupby('fish_id')['date'].rank(method='dense').astype(int)\n",
    "\n",
    "def calculate_success(row):\n",
    "    if row['Xr'] < rect_pos[0] + rect_width and criterion_Yr * (-1) < row['Yr'] < criterion_Yr:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calculate_excellent(row):\n",
    "    if row['success'] == 1 and row['distance'] < criterion_dis:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to create the 'success' column\n",
    "ReRotation_trial_new_df['success'] = ReRotation_trial_new_df.apply(calculate_success, axis=1)\n",
    "ReRotation_trial_new_df['excellent'] = ReRotation_trial_new_df.apply(calculate_excellent, axis=1)\n",
    "# Save the new DataFrame to a CSV file\n",
    "ReRotation_trial_path = r'D:\\FOV2\\BRWanalysis\\data\\ReRotation\\all_ReRotationeachtrial.csv'\n",
    "ReRotation_trial_new_df = ReRotation_trial_new_df.reset_index(drop=True)\n",
    "\n",
    "ReRotation_trial_new_df.to_csv(ReRotation_trial_path, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baseline_trial_new_df['date'] = Baseline_trial_new_df['date'].fillna('')\n",
    "Rotation_trial_new_df['date'] = Rotation_trial_new_df['date'].fillna('')\n",
    "Washout_trial_new_df['date'] = Washout_trial_new_df['date'].fillna('')\n",
    "ReRotation_trial_new_df['date'] = ReRotation_trial_new_df['date'].fillna('')\n",
    "\n",
    "# Now, convert the 'date' columns to strings\n",
    "Baseline_trial_new_df['date'] = Baseline_trial_new_df['date'].astype(str)\n",
    "Rotation_trial_new_df['date'] = Rotation_trial_new_df['date'].astype(str)\n",
    "Washout_trial_new_df['date'] = Washout_trial_new_df['date'].astype(str)\n",
    "ReRotation_trial_new_df['date'] = ReRotation_trial_new_df['date'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert each trial data into data of interest for each trialday ,  distinguish by different session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "Washout_sucedisday = 0\n",
    "Washout_sucmaxAbsyday = 0\n",
    "Washout_sucAbsYr_sumday = 0\n",
    "Washout_sucYds_sumday = 0\n",
    "Washout_sucFV_sumday = 0\n",
    "Washout_sucFVds_sumday = 0\n",
    "prev_date = None\n",
    "\n",
    "# Lists to store cumulative values\n",
    "Washout_cumulative_distances = []\n",
    "Washout_cumulative_maxAbsy = []\n",
    "Washout_cumulative_AbsYr_sum = []\n",
    "Washout_cumulative_Yds_sum = []\n",
    "Washout_cumulative_sucFV_sum = []\n",
    "Washout_cumulative_sucFVds_sum = []\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i in range(len(Washout_trial_new_df)):\n",
    "    if Washout_trial_new_df['date'][i] != prev_date:\n",
    "        # Date has changed, reset daily cumulative variables\n",
    "        Washout_sucedisday = 0\n",
    "        Washout_sucmaxAbsyday = 0\n",
    "        Washout_sucAbsYr_sumday = 0\n",
    "        Washout_sucYds_sumday = 0\n",
    "        Washout_sucFV_sumday = 0\n",
    "        Washout_sucFVds_sumday = 0\n",
    "\n",
    "    if Washout_trial_new_df['success'][i] == 1:\n",
    "        Washout_sucedisday_step = Washout_trial_new_df['distance'][i]\n",
    "        Washout_sucmaxAbsyday_step = Washout_trial_new_df['AbsMax_Yr'][i]\n",
    "        Washout_sucAbsYr_sumday_step = Washout_trial_new_df['AbsYr_sum'][i]\n",
    "        Washout_sucYds_sumday_step = Washout_trial_new_df['Yds_sum'][i]\n",
    "        Washout_sucFV_sumday_step = Washout_trial_new_df['FishV_sum'][i]\n",
    "        Washout_sucFVds_sumday_step = Washout_trial_new_df['FishVds_sum'][i]\n",
    "        Washout_sucedisday += Washout_sucedisday_step\n",
    "        Washout_sucmaxAbsyday += Washout_sucmaxAbsyday_step\n",
    "        Washout_sucAbsYr_sumday += Washout_sucAbsYr_sumday_step\n",
    "        Washout_sucYds_sumday += Washout_sucYds_sumday_step\n",
    "        Washout_sucFV_sumday += Washout_sucFV_sumday_step\n",
    "        Washout_sucFVds_sumday += Washout_sucFVds_sumday_step\n",
    "    else:\n",
    "        Washout_sucedisday_step = 0\n",
    "        Washout_sucmaxAbsyday_step = 0\n",
    "        Washout_sucAbsYr_sumday_step = 0\n",
    "        Washout_sucYds_sumday_step = 0\n",
    "        Washout_sucFV_sumday_step = 0\n",
    "        Washout_sucFVds_sumday_step = 0\n",
    "        Washout_sucmaxAbsyday += Washout_sucmaxAbsyday_step\n",
    "        Washout_sucAbsYr_sumday += Washout_sucAbsYr_sumday_step\n",
    "        Washout_sucYds_sumday += Washout_sucYds_sumday_step\n",
    "        Washout_sucFV_sumday += Washout_sucFV_sumday_step\n",
    "        Washout_sucFVds_sumday += Washout_sucFVds_sumday_step\n",
    "\n",
    "    # Append cumulative values\n",
    "    Washout_cumulative_distances.append(Washout_sucedisday)\n",
    "    Washout_cumulative_maxAbsy.append(Washout_sucmaxAbsyday)\n",
    "    Washout_cumulative_AbsYr_sum.append(Washout_sucAbsYr_sumday)\n",
    "    Washout_cumulative_Yds_sum.append(Washout_sucYds_sumday)\n",
    "    Washout_cumulative_sucFV_sum.append(Washout_sucFV_sumday)\n",
    "    Washout_cumulative_sucFVds_sum.append(Washout_sucFVds_sumday)\n",
    "\n",
    "    prev_date = Washout_trial_new_df['date'][i]\n",
    "\n",
    "# Add the cumulative columns to the DataFrame\n",
    "Washout_trial_new_df['cumulative_success_distance'] = Washout_cumulative_distances\n",
    "Washout_trial_new_df['cumulative_success_maxAbsy'] = Washout_cumulative_maxAbsy\n",
    "Washout_trial_new_df['cumulative_success_AbsYr_sum'] = Washout_cumulative_AbsYr_sum\n",
    "Washout_trial_new_df['cumulative_success_Yds_sum'] = Washout_cumulative_Yds_sum\n",
    "Washout_trial_new_df['cumulative_success_sucFV_sum'] = Washout_cumulative_sucFV_sum\n",
    "Washout_trial_new_df['cumulative_success_sucFVds_sum'] = Washout_cumulative_sucFVds_sum\n",
    "\n",
    "# Group the original table by ['fish_id', 'date'] and calculate the average values for ['time'], ['distance'], and ['AbsMax_Yr']\n",
    "Washout_grouped_data = Washout_trial_new_df.groupby(['fish_id', 'date', 'Day', 'Trialday']).agg({'time': 'mean', 'distance': 'mean', 'AbsMax_Yr': 'mean', 'AbsYr_sum': 'mean', 'Yds_sum': 'mean', 'FishV_sum': 'mean', 'FishVds_sum': 'mean', 'success': 'mean', 'excellent': 'mean'})\n",
    "\n",
    "# Reset the index of the grouped DataFrame\n",
    "Washout_grouped_data.reset_index(inplace=True)\n",
    "\n",
    "# Calculate the time of success and the time of excellent\n",
    "Wsum_data = Washout_trial_new_df.groupby(['fish_id', 'date', 'Day', 'Trialday'])[['success', 'excellent']].sum().reset_index()\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "Washout_new_table = pd.DataFrame({\n",
    "    'fish_id': Washout_grouped_data['fish_id'],\n",
    "    'date': Washout_grouped_data['date'],\n",
    "    'Day': Washout_grouped_data['Day'],\n",
    "    'Trialday': Washout_grouped_data['Trialday'],\n",
    "    'average time': Washout_grouped_data['time'],\n",
    "    'average distance': Washout_grouped_data['distance'],\n",
    "    'average maximum deviation': Washout_grouped_data['AbsMax_Yr'],\n",
    "    'average AbsYr_sum': Washout_grouped_data['AbsYr_sum'],\n",
    "    'average Yds_sum': Washout_grouped_data['Yds_sum'],\n",
    "    'average FishV_sum': Washout_grouped_data['FishV_sum'],\n",
    "    'average FishVds_sum': Washout_grouped_data['FishVds_sum'],\n",
    "    'average success rate': Washout_grouped_data['success'],\n",
    "    'average excellent rate': Washout_grouped_data['excellent'],\n",
    "    'timeofsuc': Wsum_data['success'],\n",
    "    'timeofexc': Wsum_data['excellent'],\n",
    "})\n",
    "\n",
    "Washout_trial_new_df.to_csv(Washout_trial_path, index=False)\n",
    "Washout_session_path = r'D:\\FOV2\\BRWanalysis\\data\\Washout\\all_Washoutsession.csv'\n",
    "Washout_new_table.to_csv(Washout_session_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "Rotation_sucedisday = 0\n",
    "Rotation_sucmaxAbsyday = 0\n",
    "Rotation_sucAbsYr_sumday = 0\n",
    "Rotation_sucYds_sumday = 0\n",
    "Rotation_sucFV_sumday = 0\n",
    "Rotation_sucFVds_sumday = 0\n",
    "prev_date = None\n",
    "\n",
    "# Lists to store cumulative values\n",
    "Rotation_cumulative_distances = []\n",
    "Rotation_cumulative_maxAbsy = []\n",
    "Rotation_cumulative_AbsYr_sum = []\n",
    "Rotation_cumulative_Yds_sum = []\n",
    "Rotation_cumulative_sucFV_sum = []\n",
    "Rotation_cumulative_sucFVds_sum = []\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i in range(len(Rotation_trial_new_df)):\n",
    "    if Rotation_trial_new_df['date'][i] == prev_date or prev_date is None:\n",
    "        if Rotation_trial_new_df['success'][i] == 1:\n",
    "            Rotation_sucedisday_step = Rotation_trial_new_df['distance'][i]\n",
    "            Rotation_sucmaxAbsyday_step = Rotation_trial_new_df['AbsMax_Yr'][i]\n",
    "            Rotation_sucAbsYr_sumday_step = Rotation_trial_new_df['AbsYr_sum'][i]\n",
    "            Rotation_sucYds_sumday_step = Rotation_trial_new_df['Yds_sum'][i]\n",
    "            Rotation_sucFV_sumday_step = Rotation_trial_new_df['FishV_sum'][i]\n",
    "            Rotation_sucFVds_sumday_step = Rotation_trial_new_df['FishVds_sum'][i]\n",
    "            Rotation_sucedisday += Rotation_sucedisday_step\n",
    "            Rotation_sucmaxAbsyday += Rotation_sucmaxAbsyday_step\n",
    "            Rotation_sucAbsYr_sumday += Rotation_sucAbsYr_sumday_step\n",
    "            Rotation_sucYds_sumday += Rotation_sucYds_sumday_step\n",
    "            Rotation_sucFV_sumday += Rotation_sucFV_sumday_step\n",
    "            Rotation_sucFVds_sumday += Rotation_sucFVds_sumday_step\n",
    "        else:\n",
    "            Rotation_sucedisday_step = 0\n",
    "            Rotation_sucmaxAbsyday_step = 0\n",
    "            Rotation_sucAbsYr_sumday_step = 0\n",
    "            Rotation_sucYds_sumday_step = 0\n",
    "            Rotation_sucFV_sumday_step = 0\n",
    "            Rotation_sucFVds_sumday_step = 0\n",
    "            Rotation_sucmaxAbsyday += Rotation_sucmaxAbsyday_step\n",
    "            Rotation_sucAbsYr_sumday += Rotation_sucAbsYr_sumday_step\n",
    "            Rotation_sucYds_sumday += Rotation_sucYds_sumday_step\n",
    "            Rotation_sucFV_sumday += Rotation_sucFV_sumday_step\n",
    "            Rotation_sucFVds_sumday += Rotation_sucFVds_sumday_step\n",
    "    else:\n",
    "        # Reset cumulative variables when date changes\n",
    "        Rotation_sucedisday = 0 if Rotation_trial_new_df['success'][i] != 1 else Rotation_trial_new_df['distance'][i]\n",
    "        Rotation_sucmaxAbsyday = 0\n",
    "        Rotation_sucAbsYr_sumday = 0\n",
    "        Rotation_sucYds_sumday = 0\n",
    "        Rotation_sucFV_sumday = 0\n",
    "        Rotation_sucFVds_sumday = 0\n",
    "\n",
    "    Rotation_cumulative_distances.append(Rotation_sucedisday)\n",
    "    Rotation_cumulative_maxAbsy.append(Rotation_sucmaxAbsyday)\n",
    "    Rotation_cumulative_AbsYr_sum.append(Rotation_sucAbsYr_sumday)\n",
    "    Rotation_cumulative_Yds_sum.append(Rotation_sucYds_sumday)\n",
    "    Rotation_cumulative_sucFV_sum.append(Rotation_sucFV_sumday)\n",
    "    Rotation_cumulative_sucFVds_sum.append(Rotation_sucFVds_sumday)\n",
    "\n",
    "    prev_date = Rotation_trial_new_df['date'][i]\n",
    "\n",
    "# Add the cumulative columns to the DataFrame\n",
    "Rotation_trial_new_df['cumulative_success_distance'] = Rotation_cumulative_distances\n",
    "Rotation_trial_new_df['cumulative_success_maxAbsy'] = Rotation_cumulative_maxAbsy\n",
    "Rotation_trial_new_df['cumulative_success_AbsYr_sum'] = Rotation_cumulative_AbsYr_sum\n",
    "Rotation_trial_new_df['cumulative_success_Yds_sum'] = Rotation_cumulative_Yds_sum\n",
    "Rotation_trial_new_df['cumulative_success_sucFV_sum'] = Rotation_cumulative_sucFV_sum\n",
    "Rotation_trial_new_df['cumulative_success_sucFVds_sum'] = Rotation_cumulative_sucFVds_sum\n",
    "\n",
    "# Group the original table by ['fish_id', 'date'] and calculate the average values for ['time'], ['distance'], and ['AbsMax_Yr']\n",
    "Rotation_grouped_data = Rotation_trial_new_df.groupby(['fish_id', 'date', 'Day', 'Trialday']).agg({'time': 'mean', 'distance': 'mean', 'AbsMax_Yr': 'mean', 'AbsYr_sum': 'mean', 'Yds_sum': 'mean', 'FishV_sum': 'mean', 'FishVds_sum': 'mean', 'success': 'mean', 'excellent': 'mean'})\n",
    "\n",
    "# Reset the index of the grouped DataFrame\n",
    "Rotation_grouped_data.reset_index(inplace=True)\n",
    "\n",
    "# Calculate the time of success and the time of excellent\n",
    "Rsum_data = Rotation_trial_new_df.groupby(['fish_id', 'date', 'Day', 'Trialday'])[['success', 'excellent']].sum().reset_index()\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "Rotation_new_table = pd.DataFrame({\n",
    "    'fish_id': Rotation_grouped_data['fish_id'],\n",
    "    'date': Rotation_grouped_data['date'],\n",
    "    'Day': Rotation_grouped_data['Day'],\n",
    "    'Trialday': Rotation_grouped_data['Trialday'],\n",
    "    'average time': Rotation_grouped_data['time'],\n",
    "    'average distance': Rotation_grouped_data['distance'],\n",
    "    'average maximum deviation': Rotation_grouped_data['AbsMax_Yr'],\n",
    "    'average AbsYr_sum': Rotation_grouped_data['AbsYr_sum'],\n",
    "    'average Yds_sum': Rotation_grouped_data['Yds_sum'],\n",
    "    'average FishV_sum': Rotation_grouped_data['FishV_sum'],\n",
    "    'average FishVds_sum': Rotation_grouped_data['FishVds_sum'],\n",
    "    'average success rate': Rotation_grouped_data['success'],\n",
    "    'average excellent rate': Rotation_grouped_data['excellent'],\n",
    "    'timeofsuc': Rsum_data['success'],\n",
    "    'timeofexc': Rsum_data['excellent'],\n",
    "})\n",
    "\n",
    "Rotation_trial_new_df.to_csv(Rotation_trial_path, index=False)\n",
    "Rotation_session_path = r'D:\\FOV2\\BRWanalysis\\data\\Rotation\\all_Rotationsession.csv'\n",
    "Rotation_new_table.to_csv(Rotation_session_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "ReRotation_sucedisday = 0\n",
    "ReRotation_sucmaxAbsyday = 0\n",
    "ReRotation_sucAbsYr_sumday = 0\n",
    "ReRotation_sucYds_sumday = 0\n",
    "ReRotation_sucFV_sumday = 0\n",
    "ReRotation_sucFVds_sumday = 0\n",
    "prev_date = None\n",
    "\n",
    "# Lists to store cumulative values\n",
    "ReRotation_cumulative_distances = []\n",
    "ReRotation_cumulative_maxAbsy = []\n",
    "ReRotation_cumulative_AbsYr_sum = []\n",
    "ReRotation_cumulative_Yds_sum = []\n",
    "ReRotation_cumulative_sucFV_sum = []\n",
    "ReRotation_cumulative_sucFVds_sum = []\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i in range(len(ReRotation_trial_new_df)):\n",
    "    if ReRotation_trial_new_df['date'][i] != prev_date:\n",
    "        # Date has changed, reset daily cumulative variables\n",
    "        ReRotation_sucedisday = 0\n",
    "        ReRotation_sucmaxAbsyday = 0\n",
    "        ReRotation_sucAbsYr_sumday = 0\n",
    "        ReRotation_sucYds_sumday = 0\n",
    "        ReRotation_sucFV_sumday = 0\n",
    "        ReRotation_sucFVds_sumday = 0\n",
    "\n",
    "    if ReRotation_trial_new_df['success'][i] == 1:\n",
    "        ReRotation_sucedisday_step = ReRotation_trial_new_df['distance'][i]\n",
    "        ReRotation_sucmaxAbsyday_step = ReRotation_trial_new_df['AbsMax_Yr'][i]\n",
    "        ReRotation_sucAbsYr_sumday_step = ReRotation_trial_new_df['AbsYr_sum'][i]\n",
    "        ReRotation_sucYds_sumday_step = ReRotation_trial_new_df['Yds_sum'][i]\n",
    "        ReRotation_sucFV_sumday_step = ReRotation_trial_new_df['FishV_sum'][i]\n",
    "        ReRotation_sucFVds_sumday_step = ReRotation_trial_new_df['FishVds_sum'][i]\n",
    "        ReRotation_sucedisday += ReRotation_sucedisday_step\n",
    "        ReRotation_sucmaxAbsyday += ReRotation_sucmaxAbsyday_step\n",
    "        ReRotation_sucAbsYr_sumday += ReRotation_sucAbsYr_sumday_step\n",
    "        ReRotation_sucYds_sumday += ReRotation_sucYds_sumday_step\n",
    "        ReRotation_sucFV_sumday += ReRotation_sucFV_sumday_step\n",
    "        ReRotation_sucFVds_sumday += ReRotation_sucFVds_sumday_step\n",
    "    else:\n",
    "        ReRotation_sucedisday_step = 0\n",
    "        ReRotation_sucmaxAbsyday_step = 0\n",
    "        ReRotation_sucAbsYr_sumday_step = 0\n",
    "        ReRotation_sucYds_sumday_step = 0\n",
    "        ReRotation_sucFV_sumday_step = 0\n",
    "        ReRotation_sucFVds_sumday_step = 0\n",
    "        ReRotation_sucmaxAbsyday += ReRotation_sucmaxAbsyday_step\n",
    "        ReRotation_sucAbsYr_sumday += ReRotation_sucAbsYr_sumday_step\n",
    "        ReRotation_sucYds_sumday += ReRotation_sucYds_sumday_step\n",
    "        ReRotation_sucFV_sumday += ReRotation_sucFV_sumday_step\n",
    "        ReRotation_sucFVds_sumday += ReRotation_sucFVds_sumday_step\n",
    "\n",
    "    # Append cumulative values\n",
    "    ReRotation_cumulative_distances.append(ReRotation_sucedisday)\n",
    "    ReRotation_cumulative_maxAbsy.append(ReRotation_sucmaxAbsyday)\n",
    "    ReRotation_cumulative_AbsYr_sum.append(ReRotation_sucAbsYr_sumday)\n",
    "    ReRotation_cumulative_Yds_sum.append(ReRotation_sucYds_sumday)\n",
    "    ReRotation_cumulative_sucFV_sum.append(ReRotation_sucFV_sumday)\n",
    "    ReRotation_cumulative_sucFVds_sum.append(ReRotation_sucFVds_sumday)\n",
    "\n",
    "    prev_date = ReRotation_trial_new_df['date'][i]\n",
    "\n",
    "# Add the cumulative columns to the DataFrame\n",
    "ReRotation_trial_new_df['cumulative_success_distance'] = ReRotation_cumulative_distances\n",
    "ReRotation_trial_new_df['cumulative_success_maxAbsy'] = ReRotation_cumulative_maxAbsy\n",
    "ReRotation_trial_new_df['cumulative_success_AbsYr_sum'] = ReRotation_cumulative_AbsYr_sum\n",
    "ReRotation_trial_new_df['cumulative_success_Yds_sum'] = ReRotation_cumulative_Yds_sum\n",
    "ReRotation_trial_new_df['cumulative_success_sucFV_sum'] = ReRotation_cumulative_sucFV_sum\n",
    "ReRotation_trial_new_df['cumulative_success_sucFVds_sum'] = ReRotation_cumulative_sucFVds_sum\n",
    "\n",
    "# Group the original table by ['fish_id', 'date'] and calculate the average values for ['time'], ['distance'], and ['AbsMax_Yr']\n",
    "ReRotation_grouped_data = ReRotation_trial_new_df.groupby(['fish_id', 'date', 'Day', 'Trialday']).agg({'time': 'mean', 'distance': 'mean', 'AbsMax_Yr': 'mean', 'AbsYr_sum': 'mean', 'Yds_sum': 'mean', 'FishV_sum': 'mean', 'FishVds_sum': 'mean', 'success': 'mean', 'excellent': 'mean'})\n",
    "\n",
    "# Reset the index of the grouped DataFrame\n",
    "ReRotation_grouped_data.reset_index(inplace=True)\n",
    "\n",
    "# Calculate the time of success and the time of excellent\n",
    "ReRsum_data = ReRotation_trial_new_df.groupby(['fish_id', 'date', 'Day', 'Trialday'])[['success', 'excellent']].sum().reset_index()\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "ReRotation_new_table = pd.DataFrame({\n",
    "    'fish_id': ReRotation_grouped_data['fish_id'],\n",
    "    'date': ReRotation_grouped_data['date'],\n",
    "    'Day': ReRotation_grouped_data['Day'],\n",
    "    'Trialday': ReRotation_grouped_data['Trialday'],\n",
    "    'average time': ReRotation_grouped_data['time'],\n",
    "    'average distance': ReRotation_grouped_data['distance'],\n",
    "    'average maximum deviation': ReRotation_grouped_data['AbsMax_Yr'],\n",
    "    'average AbsYr_sum': ReRotation_grouped_data['AbsYr_sum'],\n",
    "    'average Yds_sum': ReRotation_grouped_data['Yds_sum'],\n",
    "    'average FishV_sum': ReRotation_grouped_data['FishV_sum'],\n",
    "    'average FishVds_sum': ReRotation_grouped_data['FishVds_sum'],\n",
    "    'average success rate': ReRotation_grouped_data['success'],\n",
    "    'average excellent rate': ReRotation_grouped_data['excellent'],\n",
    "    'timeofsuc': ReRsum_data['success'],\n",
    "    'timeofexc': ReRsum_data['excellent'],\n",
    "})\n",
    "\n",
    "ReRotation_trial_new_df.to_csv(ReRotation_trial_path, index=False)\n",
    "ReRotation_session_path = r'D:\\FOV2\\BRWanalysis\\data\\ReRotation\\all_ReRotationsession.csv'\n",
    "ReRotation_new_table.to_csv(ReRotation_session_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "Baseline_sucedisday = 0\n",
    "Baseline_sucmaxAbsyday = 0\n",
    "Baseline_sucAbsYr_sumday = 0\n",
    "Baseline_sucYds_sumday = 0\n",
    "Baseline_sucFV_sumday = 0\n",
    "Baseline_sucFVds_sumday = 0\n",
    "prev_date = None\n",
    "\n",
    "# Lists to store cumulative values\n",
    "Baseline_cumulative_distances = []\n",
    "Baseline_cumulative_maxAbsy = []\n",
    "Baseline_cumulative_AbsYr_sum = []\n",
    "Baseline_cumulative_Yds_sum = []\n",
    "Baseline_cumulative_sucFV_sum = []\n",
    "Baseline_cumulative_sucFVds_sum = []\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i in range(len(Baseline_trial_new_df)):\n",
    "    if Baseline_trial_new_df['date'][i] != prev_date:\n",
    "        # Date has changed, reset daily cumulative variables\n",
    "        Baseline_sucedisday = 0\n",
    "        Baseline_sucmaxAbsyday = 0\n",
    "        Baseline_sucAbsYr_sumday = 0\n",
    "        Baseline_sucYds_sumday = 0\n",
    "        Baseline_sucFV_sumday = 0\n",
    "        Baseline_sucFVds_sumday = 0\n",
    "\n",
    "    if Baseline_trial_new_df['success'][i] == 1:\n",
    "        Baseline_sucedisday_step = Baseline_trial_new_df['distance'][i]\n",
    "        Baseline_sucmaxAbsyday_step = Baseline_trial_new_df['AbsMax_Yr'][i]\n",
    "        Baseline_sucAbsYr_sumday_step = Baseline_trial_new_df['AbsYr_sum'][i]\n",
    "        Baseline_sucYds_sumday_step = Baseline_trial_new_df['Yds_sum'][i]\n",
    "        Baseline_sucFV_sumday_step = Baseline_trial_new_df['FishV_sum'][i]\n",
    "        Baseline_sucFVds_sumday_step = Baseline_trial_new_df['FishVds_sum'][i]\n",
    "        Baseline_sucedisday += Baseline_sucedisday_step\n",
    "        Baseline_sucmaxAbsyday += Baseline_sucmaxAbsyday_step\n",
    "        Baseline_sucAbsYr_sumday += Baseline_sucAbsYr_sumday_step\n",
    "        Baseline_sucYds_sumday += Baseline_sucYds_sumday_step\n",
    "        Baseline_sucFV_sumday += Baseline_sucFV_sumday_step\n",
    "        Baseline_sucFVds_sumday += Baseline_sucFVds_sumday_step\n",
    "    else:\n",
    "        Baseline_sucedisday_step = 0\n",
    "        Baseline_sucmaxAbsyday_step = 0\n",
    "        Baseline_sucAbsYr_sumday_step = 0\n",
    "        Baseline_sucYds_sumday_step = 0\n",
    "        Baseline_sucFV_sumday_step = 0\n",
    "        Baseline_sucFVds_sumday_step = 0\n",
    "        Baseline_sucmaxAbsyday += Baseline_sucmaxAbsyday_step\n",
    "        Baseline_sucAbsYr_sumday += Baseline_sucAbsYr_sumday_step\n",
    "        Baseline_sucYds_sumday += Baseline_sucYds_sumday_step\n",
    "        Baseline_sucFV_sumday += Baseline_sucFV_sumday_step\n",
    "        Baseline_sucFVds_sumday += Baseline_sucFVds_sumday_step\n",
    "\n",
    "    # Append cumulative values\n",
    "    Baseline_cumulative_distances.append(Baseline_sucedisday)\n",
    "    Baseline_cumulative_maxAbsy.append(Baseline_sucmaxAbsyday)\n",
    "    Baseline_cumulative_AbsYr_sum.append(Baseline_sucAbsYr_sumday)\n",
    "    Baseline_cumulative_Yds_sum.append(Baseline_sucYds_sumday)\n",
    "    Baseline_cumulative_sucFV_sum.append(Baseline_sucFV_sumday)\n",
    "    Baseline_cumulative_sucFVds_sum.append(Baseline_sucFVds_sumday)\n",
    "\n",
    "    prev_date = Baseline_trial_new_df['date'][i]\n",
    "\n",
    "# Add the cumulative columns to the DataFrame\n",
    "Baseline_trial_new_df['cumulative_success_distance'] = Baseline_cumulative_distances\n",
    "Baseline_trial_new_df['cumulative_success_maxAbsy'] = Baseline_cumulative_maxAbsy\n",
    "Baseline_trial_new_df['cumulative_success_AbsYr_sum'] = Baseline_cumulative_AbsYr_sum\n",
    "Baseline_trial_new_df['cumulative_success_Yds_sum'] = Baseline_cumulative_Yds_sum\n",
    "Baseline_trial_new_df['cumulative_success_sucFV_sum'] = Baseline_cumulative_sucFV_sum\n",
    "Baseline_trial_new_df['cumulative_success_sucFVds_sum'] = Baseline_cumulative_sucFVds_sum\n",
    "\n",
    "# Group the original table by ['fish_id', 'date'] and calculate the average values for ['time'], ['distance'], and ['AbsMax_Yr']\n",
    "Baseline_grouped_data = Baseline_trial_new_df.groupby(['fish_id', 'date', 'Day', 'Trialday']).agg({'time': 'mean', 'distance': 'mean', 'AbsMax_Yr': 'mean', 'AbsYr_sum': 'mean', 'Yds_sum': 'mean', 'FishV_sum': 'mean', 'FishVds_sum': 'mean', 'success': 'mean', 'excellent': 'mean'})\n",
    "\n",
    "# Reset the index of the grouped DataFrame\n",
    "Baseline_grouped_data.reset_index(inplace=True)\n",
    "\n",
    "# Calculate the time of success and the time of excellent\n",
    "Bsum_data = Baseline_trial_new_df.groupby(['fish_id', 'date', 'Day', 'Trialday'])[['success', 'excellent']].sum().reset_index()\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "Baseline_new_table = pd.DataFrame({\n",
    "    'fish_id': Baseline_grouped_data['fish_id'],\n",
    "    'date': Baseline_grouped_data['date'],\n",
    "    'Day': Baseline_grouped_data['Day'],\n",
    "    'Trialday': Baseline_grouped_data['Trialday'],\n",
    "    'average time': Baseline_grouped_data['time'],\n",
    "    'average distance': Baseline_grouped_data['distance'],\n",
    "    'average maximum deviation': Baseline_grouped_data['AbsMax_Yr'],\n",
    "    'average AbsYr_sum': Baseline_grouped_data['AbsYr_sum'],\n",
    "    'average Yds_sum': Baseline_grouped_data['Yds_sum'],\n",
    "    'average FishV_sum': Baseline_grouped_data['FishV_sum'],\n",
    "    'average FishVds_sum': Baseline_grouped_data['FishVds_sum'],\n",
    "    'average success rate': Baseline_grouped_data['success'],\n",
    "    'average excellent rate': Baseline_grouped_data['excellent'],\n",
    "    'timeofsuc': Bsum_data['success'],\n",
    "    'timeofexc': Bsum_data['excellent'],\n",
    "})\n",
    "\n",
    "Baseline_trial_new_df.to_csv(Baseline_trial_path, index=False)\n",
    "Baseline_session_path = r'D:\\FOV2\\BRWanalysis\\data\\Baseline\\all_Baselinesession.csv'\n",
    "Baseline_new_table.to_csv(Baseline_session_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2800731509.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brows_before_date_change.loc[i, 'average_success_distance'] = Brows_before_date_change.loc[i, 'cumulative_success_distance'] / Baseline_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2800731509.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brows_before_date_change.loc[i, 'average_success_maxAbsy'] = Brows_before_date_change.loc[i, 'cumulative_success_maxAbsy'] / Baseline_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2800731509.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = Brows_before_date_change.loc[i, 'cumulative_success_AbsYr_sum'] / Baseline_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2800731509.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brows_before_date_change.loc[i, 'average_success_Yds_sum'] = Brows_before_date_change.loc[i, 'cumulative_success_Yds_sum'] / Baseline_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2800731509.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brows_before_date_change.loc[i, 'average_success_FV_sum'] = Brows_before_date_change.loc[i, 'cumulative_success_sucFV_sum'] / Baseline_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\2800731509.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brows_before_date_change.loc[i, 'average_success_FVds_sum'] =Brows_before_date_change.loc[i, 'cumulative_success_sucFVds_sum'] / Baseline_new_table.loc[i, 'timeofsuc']\n"
     ]
    }
   ],
   "source": [
    "# Create a mask to identify the rows where 'date' changes\n",
    "Bdate_change_mask = Baseline_trial_new_df['date'] != Baseline_trial_new_df['date'].shift(-1)\n",
    "\n",
    "\n",
    "# Use the mask to extract the rows before the date changes\n",
    "Brows_before_date_change = Baseline_trial_new_df[Bdate_change_mask]\n",
    "\n",
    "# Reset the index of rows_before_date_change and summary DataFrames\n",
    "Brows_before_date_change.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(Brows_before_date_change)):\n",
    "    if Baseline_new_table.loc[i, 'timeofsuc'] != 0:\n",
    "        Brows_before_date_change.loc[i, 'average_success_distance'] = Brows_before_date_change.loc[i, 'cumulative_success_distance'] / Baseline_new_table.loc[i, 'timeofsuc']\n",
    "        Brows_before_date_change.loc[i, 'average_success_maxAbsy'] = Brows_before_date_change.loc[i, 'cumulative_success_maxAbsy'] / Baseline_new_table.loc[i, 'timeofsuc']\n",
    "        Brows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = Brows_before_date_change.loc[i, 'cumulative_success_AbsYr_sum'] / Baseline_new_table.loc[i, 'timeofsuc']\n",
    "        Brows_before_date_change.loc[i, 'average_success_Yds_sum'] = Brows_before_date_change.loc[i, 'cumulative_success_Yds_sum'] / Baseline_new_table.loc[i, 'timeofsuc']\n",
    "        Brows_before_date_change.loc[i, 'average_success_FV_sum'] = Brows_before_date_change.loc[i, 'cumulative_success_sucFV_sum'] / Baseline_new_table.loc[i, 'timeofsuc']\n",
    "        Brows_before_date_change.loc[i, 'average_success_FVds_sum'] =Brows_before_date_change.loc[i, 'cumulative_success_sucFVds_sum'] / Baseline_new_table.loc[i, 'timeofsuc']\n",
    "    else:\n",
    "        Brows_before_date_change.loc[i, 'average_success_distance'] = 0\n",
    "        Brows_before_date_change.loc[i, 'average_success_maxAbsy'] = 0\n",
    "        Brows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = 0\n",
    "        Brows_before_date_change.loc[i, 'average_success_Yds_sum'] = 0\n",
    "        Brows_before_date_change.loc[i, 'average_success_FV_sum'] = 0\n",
    "        Brows_before_date_change.loc[i, 'average_success_FVds_sum'] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Brows_before_date_change = Brows_before_date_change.reset_index()\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "Baseline_new_table = pd.DataFrame({\n",
    "    'fish_id': Baseline_grouped_data['fish_id'],\n",
    "    'date': Baseline_grouped_data['date'],\n",
    "    'Day': Baseline_grouped_data['Day'],\n",
    "    'Trialday': Baseline_grouped_data['Trialday'],\n",
    "    'average time': Baseline_grouped_data['time'],\n",
    "    'average distance':Baseline_grouped_data['distance'],\n",
    "    'average distance': Baseline_grouped_data['distance'],\n",
    "    'average maximum deviation': Baseline_grouped_data['AbsMax_Yr'],\n",
    "    'average AbsYr_sum': Baseline_grouped_data['AbsYr_sum'],\n",
    "    'average Yds_sum': Baseline_grouped_data['Yds_sum'],\n",
    "    'average FishV_sum': Baseline_grouped_data['FishV_sum'],\n",
    "    'average FishVds_sum': Baseline_grouped_data['FishVds_sum'],\n",
    "    'average success rate': Baseline_grouped_data['success'],\n",
    "    'average excellent rate': Baseline_grouped_data['excellent'],\n",
    "    'timeofsuc': Bsum_data['success'],\n",
    "    'timeofexc': Bsum_data['excellent'],\n",
    "    'average_success_distance':Brows_before_date_change['average_success_distance'],\n",
    "    'average_success_maxAbsy':Brows_before_date_change['average_success_maxAbsy'],\n",
    "    'average_success_AbsYr_sum':Brows_before_date_change['average_success_AbsYr_sum'],\n",
    "    'average_success_Yds_sum':Brows_before_date_change['average_success_Yds_sum'],\n",
    "    'average_success_FV_sum':Brows_before_date_change['average_success_FV_sum'],\n",
    "    'average_success_FVds_sum':Brows_before_date_change['average_success_FVds_sum']\n",
    "\n",
    "\n",
    "\n",
    "})\n",
    "\n",
    "Baseline_trial_new_df.to_csv(Baseline_trial_path, index=True)\n",
    "\n",
    "Baseline_new_table.to_csv(Baseline_session_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\1857559753.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Rrows_before_date_change.loc[i, 'average_success_distance'] = Rrows_before_date_change.loc[i, 'cumulative_success_distance'] / Rotation_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\1857559753.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Rrows_before_date_change.loc[i, 'average_success_maxAbsy'] = Rrows_before_date_change.loc[i, 'cumulative_success_maxAbsy'] / Rotation_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\1857559753.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Rrows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = Rrows_before_date_change.loc[i, 'cumulative_success_AbsYr_sum'] / Rotation_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\1857559753.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Rrows_before_date_change.loc[i, 'average_success_Yds_sum'] = Rrows_before_date_change.loc[i, 'cumulative_success_Yds_sum'] / Rotation_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\1857559753.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Rrows_before_date_change.loc[i, 'average_success_FV_sum'] = Rrows_before_date_change.loc[i, 'cumulative_success_sucFV_sum'] / Rotation_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\1857559753.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Rrows_before_date_change.loc[i, 'average_success_FVds_sum'] = Rrows_before_date_change.loc[i, 'cumulative_success_sucFVds_sum'] / Rotation_new_table.loc[i, 'timeofsuc']\n"
     ]
    }
   ],
   "source": [
    "# Create a mask to identify the rows where 'date' changes\n",
    "Rdate_change_mask = Rotation_trial_new_df['date'] != Rotation_trial_new_df['date'].shift(-1)\n",
    "\n",
    "# Use the mask to extract the rows before the date changes\n",
    "Rrows_before_date_change = Rotation_trial_new_df[Rdate_change_mask]\n",
    "\n",
    "# Reset the index of rows_before_date_change and summary DataFrames\n",
    "Rrows_before_date_change.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(len(Rrows_before_date_change)):\n",
    "    if Rotation_new_table.loc[i, 'timeofsuc'] != 0:\n",
    "        Rrows_before_date_change.loc[i, 'average_success_distance'] = Rrows_before_date_change.loc[i, 'cumulative_success_distance'] / Rotation_new_table.loc[i, 'timeofsuc']\n",
    "        Rrows_before_date_change.loc[i, 'average_success_maxAbsy'] = Rrows_before_date_change.loc[i, 'cumulative_success_maxAbsy'] / Rotation_new_table.loc[i, 'timeofsuc']\n",
    "        Rrows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = Rrows_before_date_change.loc[i, 'cumulative_success_AbsYr_sum'] / Rotation_new_table.loc[i, 'timeofsuc']\n",
    "        Rrows_before_date_change.loc[i, 'average_success_Yds_sum'] = Rrows_before_date_change.loc[i, 'cumulative_success_Yds_sum'] / Rotation_new_table.loc[i, 'timeofsuc']\n",
    "        Rrows_before_date_change.loc[i, 'average_success_FV_sum'] = Rrows_before_date_change.loc[i, 'cumulative_success_sucFV_sum'] / Rotation_new_table.loc[i, 'timeofsuc']\n",
    "        Rrows_before_date_change.loc[i, 'average_success_FVds_sum'] = Rrows_before_date_change.loc[i, 'cumulative_success_sucFVds_sum'] / Rotation_new_table.loc[i, 'timeofsuc']\n",
    "    else:\n",
    "        Rrows_before_date_change.loc[i, 'average_success_distance'] = 0\n",
    "        Rrows_before_date_change.loc[i, 'average_success_maxAbsy'] = 0\n",
    "        Rrows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = 0\n",
    "        Rrows_before_date_change.loc[i, 'average_success_Yds_sum'] = 0\n",
    "        Rrows_before_date_change.loc[i, 'average_success_FV_sum'] = 0\n",
    "        Rrows_before_date_change.loc[i, 'average_success_FVds_sum'] = 0\n",
    "\n",
    "Rrows_before_date_change = Rrows_before_date_change.reset_index()\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "Rotation_new_table = pd.DataFrame({\n",
    "    'fish_id': Rotation_grouped_data['fish_id'],\n",
    "    'date': Rotation_grouped_data['date'],\n",
    "    'Day': Rotation_grouped_data['Day'],\n",
    "    'Trialday': Rotation_grouped_data['Trialday'],\n",
    "    'average time': Rotation_grouped_data['time'],\n",
    "    'average distance': Rotation_grouped_data['distance'],\n",
    "    'average distance': Rotation_grouped_data['distance'],\n",
    "    'average maximum deviation': Rotation_grouped_data['AbsMax_Yr'],\n",
    "    'average AbsYr_sum': Rotation_grouped_data['AbsYr_sum'],\n",
    "    'average Yds_sum': Rotation_grouped_data['Yds_sum'],\n",
    "    'average FishV_sum': Rotation_grouped_data['FishV_sum'],\n",
    "    'average FishVds_sum': Rotation_grouped_data['FishVds_sum'],\n",
    "    'average success rate': Rotation_grouped_data['success'],\n",
    "    'average excellent rate': Rotation_grouped_data['excellent'],\n",
    "    'timeofsuc': Rsum_data['success'],\n",
    "    'timeofexc': Rsum_data['excellent'],\n",
    "    'average_success_distance': Rrows_before_date_change['average_success_distance'],\n",
    "    'average_success_maxAbsy': Rrows_before_date_change['average_success_maxAbsy'],\n",
    "    'average_success_AbsYr_sum': Rrows_before_date_change['average_success_AbsYr_sum'],\n",
    "    'average_success_Yds_sum': Rrows_before_date_change['average_success_Yds_sum'],\n",
    "    'average_success_FV_sum': Rrows_before_date_change['average_success_FV_sum'],\n",
    "    'average_success_FVds_sum': Rrows_before_date_change['average_success_FVds_sum']\n",
    "})\n",
    "\n",
    "Rotation_trial_new_df.to_csv(Rotation_trial_path, index=True)\n",
    "\n",
    "Rotation_new_table.to_csv(Rotation_session_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\1289737470.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  ReRrows_before_date_change = ReRotation_trial_new_df[Rdate_change_mask]\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\1289737470.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ReRrows_before_date_change.loc[i, 'average_success_distance'] = ReRrows_before_date_change.loc[i, 'cumulative_success_distance'] / ReRotation_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\1289737470.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ReRrows_before_date_change.loc[i, 'average_success_maxAbsy'] = ReRrows_before_date_change.loc[i, 'cumulative_success_maxAbsy'] / ReRotation_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\1289737470.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ReRrows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = ReRrows_before_date_change.loc[i, 'cumulative_success_AbsYr_sum'] / ReRotation_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\1289737470.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ReRrows_before_date_change.loc[i, 'average_success_Yds_sum'] = ReRrows_before_date_change.loc[i, 'cumulative_success_Yds_sum'] / ReRotation_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\1289737470.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ReRrows_before_date_change.loc[i, 'average_success_FV_sum'] = ReRrows_before_date_change.loc[i, 'cumulative_success_sucFV_sum'] / ReRotation_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\1289737470.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ReRrows_before_date_change.loc[i, 'average_success_FVds_sum'] = ReRrows_before_date_change.loc[i, 'cumulative_success_sucFVds_sum'] / ReRotation_new_table.loc[i, 'timeofsuc']\n"
     ]
    }
   ],
   "source": [
    "# Create a mask to identify the rows where 'date' changes\n",
    "ReRdate_change_mask = ReRotation_trial_new_df['date'] != ReRotation_trial_new_df['date'].shift(-1)\n",
    "\n",
    "# Use the mask to extract the rows before the date changes\n",
    "ReRrows_before_date_change = ReRotation_trial_new_df[Rdate_change_mask]\n",
    "\n",
    "# Reset the index of rows_before_date_change and summary DataFrames\n",
    "ReRrows_before_date_change.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(len(ReRrows_before_date_change)):\n",
    "    if ReRotation_new_table.loc[i, 'timeofsuc'] != 0:\n",
    "        ReRrows_before_date_change.loc[i, 'average_success_distance'] = ReRrows_before_date_change.loc[i, 'cumulative_success_distance'] / ReRotation_new_table.loc[i, 'timeofsuc']\n",
    "        ReRrows_before_date_change.loc[i, 'average_success_maxAbsy'] = ReRrows_before_date_change.loc[i, 'cumulative_success_maxAbsy'] / ReRotation_new_table.loc[i, 'timeofsuc']\n",
    "        ReRrows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = ReRrows_before_date_change.loc[i, 'cumulative_success_AbsYr_sum'] / ReRotation_new_table.loc[i, 'timeofsuc']\n",
    "        ReRrows_before_date_change.loc[i, 'average_success_Yds_sum'] = ReRrows_before_date_change.loc[i, 'cumulative_success_Yds_sum'] / ReRotation_new_table.loc[i, 'timeofsuc']\n",
    "        ReRrows_before_date_change.loc[i, 'average_success_FV_sum'] = ReRrows_before_date_change.loc[i, 'cumulative_success_sucFV_sum'] / ReRotation_new_table.loc[i, 'timeofsuc']\n",
    "        ReRrows_before_date_change.loc[i, 'average_success_FVds_sum'] = ReRrows_before_date_change.loc[i, 'cumulative_success_sucFVds_sum'] / ReRotation_new_table.loc[i, 'timeofsuc']\n",
    "    else:\n",
    "        ReRrows_before_date_change.loc[i, 'average_success_distance'] = 0\n",
    "        ReRrows_before_date_change.loc[i, 'average_success_maxAbsy'] = 0\n",
    "        ReRrows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = 0\n",
    "        ReRrows_before_date_change.loc[i, 'average_success_Yds_sum'] = 0\n",
    "        ReRrows_before_date_change.loc[i, 'average_success_FV_sum'] = 0\n",
    "        ReRrows_before_date_change.loc[i, 'average_success_FVds_sum'] = 0\n",
    "\n",
    "ReRrows_before_date_change = ReRrows_before_date_change.reset_index()\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "ReRotation_new_table = pd.DataFrame({\n",
    "    'fish_id': ReRotation_grouped_data['fish_id'],\n",
    "    'date': ReRotation_grouped_data['date'],\n",
    "    'Day': ReRotation_grouped_data['Day'],\n",
    "    'Trialday': ReRotation_grouped_data['Trialday'],\n",
    "    'average time': ReRotation_grouped_data['time'],\n",
    "    'average distance': ReRotation_grouped_data['distance'],\n",
    "    'average distance': ReRotation_grouped_data['distance'],\n",
    "    'average maximum deviation': ReRotation_grouped_data['AbsMax_Yr'],\n",
    "    'average AbsYr_sum': ReRotation_grouped_data['AbsYr_sum'],\n",
    "    'average Yds_sum': ReRotation_grouped_data['Yds_sum'],\n",
    "    'average FishV_sum': ReRotation_grouped_data['FishV_sum'],\n",
    "    'average FishVds_sum': ReRotation_grouped_data['FishVds_sum'],\n",
    "    'average success rate': ReRotation_grouped_data['success'],\n",
    "    'average excellent rate': ReRotation_grouped_data['excellent'],\n",
    "    'timeofsuc': ReRsum_data['success'],\n",
    "    'timeofexc': ReRsum_data['excellent'],\n",
    "    'average_success_distance': ReRrows_before_date_change['average_success_distance'],\n",
    "    'average_success_maxAbsy': ReRrows_before_date_change['average_success_maxAbsy'],\n",
    "    'average_success_AbsYr_sum': ReRrows_before_date_change['average_success_AbsYr_sum'],\n",
    "    'average_success_Yds_sum': ReRrows_before_date_change['average_success_Yds_sum'],\n",
    "    'average_success_FV_sum': ReRrows_before_date_change['average_success_FV_sum'],\n",
    "    'average_success_FVds_sum': ReRrows_before_date_change['average_success_FVds_sum']\n",
    "})\n",
    "\n",
    "ReRotation_trial_new_df.to_csv(ReRotation_trial_path, index=True)\n",
    "\n",
    "ReRotation_new_table.to_csv(ReRotation_session_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\762474465.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Wrows_before_date_change.loc[i, 'average_success_distance'] = Wrows_before_date_change.loc[i, 'cumulative_success_distance'] / Washout_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\762474465.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Wrows_before_date_change.loc[i, 'average_success_maxAbsy'] = Wrows_before_date_change.loc[i, 'cumulative_success_maxAbsy'] / Washout_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\762474465.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Wrows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = Wrows_before_date_change.loc[i, 'cumulative_success_AbsYr_sum'] / Washout_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\762474465.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Wrows_before_date_change.loc[i, 'average_success_Yds_sum'] = Wrows_before_date_change.loc[i, 'cumulative_success_Yds_sum'] / Washout_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\762474465.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Wrows_before_date_change.loc[i, 'average_success_FV_sum'] = Wrows_before_date_change.loc[i, 'cumulative_success_sucFV_sum'] / Washout_new_table.loc[i, 'timeofsuc']\n",
      "C:\\Users\\86153\\AppData\\Local\\Temp\\ipykernel_39584\\762474465.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Wrows_before_date_change.loc[i, 'average_success_FVds_sum'] = Wrows_before_date_change.loc[i, 'cumulative_success_sucFVds_sum'] / Washout_new_table.loc[i, 'timeofsuc']\n"
     ]
    }
   ],
   "source": [
    "# Create a mask to identify the rows where 'date' changes\n",
    "Wdate_change_mask = Washout_trial_new_df['date'] != Washout_trial_new_df['date'].shift(-1)\n",
    "\n",
    "# Use the mask to extract the rows before the date changes\n",
    "Wrows_before_date_change = Washout_trial_new_df[Wdate_change_mask]\n",
    "\n",
    "# Reset the index of rows_before_date_change and summary DataFrames\n",
    "Wrows_before_date_change.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(len(Wrows_before_date_change)):\n",
    "    if Washout_new_table.loc[i, 'timeofsuc'] != 0:\n",
    "        Wrows_before_date_change.loc[i, 'average_success_distance'] = Wrows_before_date_change.loc[i, 'cumulative_success_distance'] / Washout_new_table.loc[i, 'timeofsuc']\n",
    "        Wrows_before_date_change.loc[i, 'average_success_maxAbsy'] = Wrows_before_date_change.loc[i, 'cumulative_success_maxAbsy'] / Washout_new_table.loc[i, 'timeofsuc']\n",
    "        Wrows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = Wrows_before_date_change.loc[i, 'cumulative_success_AbsYr_sum'] / Washout_new_table.loc[i, 'timeofsuc']\n",
    "        Wrows_before_date_change.loc[i, 'average_success_Yds_sum'] = Wrows_before_date_change.loc[i, 'cumulative_success_Yds_sum'] / Washout_new_table.loc[i, 'timeofsuc']\n",
    "        Wrows_before_date_change.loc[i, 'average_success_FV_sum'] = Wrows_before_date_change.loc[i, 'cumulative_success_sucFV_sum'] / Washout_new_table.loc[i, 'timeofsuc']\n",
    "        Wrows_before_date_change.loc[i, 'average_success_FVds_sum'] = Wrows_before_date_change.loc[i, 'cumulative_success_sucFVds_sum'] / Washout_new_table.loc[i, 'timeofsuc']\n",
    "    else:\n",
    "        Wrows_before_date_change.loc[i, 'average_success_distance'] = 0\n",
    "        Wrows_before_date_change.loc[i, 'average_success_maxAbsy'] = 0\n",
    "        Wrows_before_date_change.loc[i, 'average_success_AbsYr_sum'] = 0\n",
    "        Wrows_before_date_change.loc[i, 'average_success_Yds_sum'] = 0\n",
    "        Wrows_before_date_change.loc[i, 'average_success_FV_sum'] = 0\n",
    "        Wrows_before_date_change.loc[i, 'average_success_FVds_sum'] = 0\n",
    "\n",
    "Wrows_before_date_change = Wrows_before_date_change.reset_index()\n",
    "\n",
    "# Create a new DataFrame with the required columns\n",
    "Washout_new_table = pd.DataFrame({\n",
    "    'fish_id': Washout_grouped_data['fish_id'],\n",
    "    'date': Washout_grouped_data['date'],\n",
    "    'Day': Washout_grouped_data['Day'],\n",
    "    'Trialday': Washout_grouped_data['Trialday'],\n",
    "    'average time': Washout_grouped_data['time'],\n",
    "    'average distance': Washout_grouped_data['distance'],\n",
    "    'average distance': Washout_grouped_data['distance'],\n",
    "    'average maximum deviation': Washout_grouped_data['AbsMax_Yr'],\n",
    "    'average AbsYr_sum': Washout_grouped_data['AbsYr_sum'],\n",
    "    'average Yds_sum': Washout_grouped_data['Yds_sum'],\n",
    "    'average FishV_sum': Washout_grouped_data['FishV_sum'],\n",
    "    'average FishVds_sum': Washout_grouped_data['FishVds_sum'],\n",
    "    'average success rate': Washout_grouped_data['success'],\n",
    "    'average excellent rate': Washout_grouped_data['excellent'],\n",
    "    'timeofsuc': Wsum_data['success'],\n",
    "    'timeofexc': Wsum_data['excellent'],\n",
    "    'average_success_distance': Wrows_before_date_change['average_success_distance'],\n",
    "    'average_success_maxAbsy': Wrows_before_date_change['average_success_maxAbsy'],\n",
    "    'average_success_AbsYr_sum': Wrows_before_date_change['average_success_AbsYr_sum'],\n",
    "    'average_success_Yds_sum': Wrows_before_date_change['average_success_Yds_sum'],\n",
    "    'average_success_FV_sum': Wrows_before_date_change['average_success_FV_sum'],\n",
    "    'average_success_FVds_sum': Wrows_before_date_change['average_success_FVds_sum']\n",
    "})\n",
    "\n",
    "Washout_trial_new_df.to_csv(Washout_trial_path, index=True)\n",
    "\n",
    "Washout_new_table.to_csv(Washout_session_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coolplots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
